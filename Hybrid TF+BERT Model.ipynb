{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1420c9-30c6-43df-baff-0ba872c91fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Function to clear memory\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8fdf65-4b57-4a43-b8cc-59be6c84071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c65fd6b-154e-48fe-b873-941b68993dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a1db60-da53-454f-b83c-d18854b876f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316a9ef7-ca02-4913-be88-2f20b7caf0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: remotezip in /opt/conda/lib/python3.10/site-packages (0.12.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from remotezip) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->remotezip) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install remotezip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ab6a1f-d31c-48a0-9e98-2b9f54db4af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.10/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9403a400-c130-45e9-be42-3477944fe1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 22:49:35.770001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "#import cv2\n",
    "import einops\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c122d5-9538-4770-a83e-3d241aba7235",
   "metadata": {},
   "source": [
    "# Load in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e5eca74-c65e-42ec-80f9-fe4ef06a8479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Link</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>sort_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.tiktok.com/@1tashyat/video/7359361...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ST Anselm College. She's a Republican. This w...</td>\n",
       "      <td>1_mp4_trial_2.json</td>\n",
       "      <td>ST Anselm College. She's a Republican. This wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://www.tiktok.com/@monkeman317/video/7357...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Said though, that if you did run for presiden...</td>\n",
       "      <td>2_mp4_trial_2.json</td>\n",
       "      <td>Said though, that if you did run for president...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://www.tiktok.com/@bwtgrils_/video/736257...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah.'</td>\n",
       "      <td>3_mp4_trial_2.json</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                               Link  Label  \\\n",
       "0    1.0  https://www.tiktok.com/@1tashyat/video/7359361...      1   \n",
       "1    2.0  https://www.tiktok.com/@monkeman317/video/7357...      1   \n",
       "2    3.0  https://www.tiktok.com/@bwtgrils_/video/736257...      1   \n",
       "\n",
       "                                                Text            FileName  \\\n",
       "0  \"ST Anselm College. She's a Republican. This w...  1_mp4_trial_2.json   \n",
       "1  \"Said though, that if you did run for presiden...  2_mp4_trial_2.json   \n",
       "2                                             Yeah.'  3_mp4_trial_2.json   \n",
       "\n",
       "                                       Transcription  sort_key  \n",
       "0  ST Anselm College. She's a Republican. This wi...         1  \n",
       "1  Said though, that if you did run for president...         2  \n",
       "2                                              Yeah.         3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_final.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1004ed8-aaf1-4d78-aa21-e48e1eae81ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Link</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>sort_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.tiktok.com/@1tashyat/video/7359361...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ST Anselm College. She's a Republican. This w...</td>\n",
       "      <td>1_mp4_trial_2.json</td>\n",
       "      <td>ST Anselm College. She's a Republican. This wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://www.tiktok.com/@monkeman317/video/7357...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Said though, that if you did run for presiden...</td>\n",
       "      <td>2_mp4_trial_2.json</td>\n",
       "      <td>Said though, that if you did run for president...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://www.tiktok.com/@bwtgrils_/video/736257...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah.'</td>\n",
       "      <td>3_mp4_trial_2.json</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                               Link  Label  \\\n",
       "0    1.0  https://www.tiktok.com/@1tashyat/video/7359361...      1   \n",
       "1    2.0  https://www.tiktok.com/@monkeman317/video/7357...      1   \n",
       "2    3.0  https://www.tiktok.com/@bwtgrils_/video/736257...      1   \n",
       "\n",
       "                                                Text            FileName  \\\n",
       "0  \"ST Anselm College. She's a Republican. This w...  1_mp4_trial_2.json   \n",
       "1  \"Said though, that if you did run for presiden...  2_mp4_trial_2.json   \n",
       "2                                             Yeah.'  3_mp4_trial_2.json   \n",
       "\n",
       "                                       Transcription  sort_key  \n",
       "0  ST Anselm College. She's a Republican. This wi...         1  \n",
       "1  Said though, that if you did run for president...         2  \n",
       "2                                              Yeah.         3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_mapping = {'Anti - Biden': 1, 'Pro - Biden': 2, 'Neutral':0, 'Anti-Biden': 1, 'Pro-Biden': 2, 'Anti-biden': 1, 'anti-Biden': 1, 'Anti-Biden ': 1, 'Neutral ':0, 'Po-Biden': 2, 'Pro-biden': 2, 'Pro-Biden ': 2}\n",
    "\n",
    "df = df.replace(replacement_mapping)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4449239-7f4d-4acf-8baf-d18fe952aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Index'].fillna(0, inplace=True)\n",
    "#df = df[df['Index'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e718108-81fb-42f0-8147-ccfde781d061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Link</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>sort_key</th>\n",
       "      <th>Video Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.tiktok.com/@1tashyat/video/7359361...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ST Anselm College. She's a Republican. This w...</td>\n",
       "      <td>1_mp4_trial_2.json</td>\n",
       "      <td>ST Anselm College. She's a Republican. This wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>video1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://www.tiktok.com/@monkeman317/video/7357...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Said though, that if you did run for presiden...</td>\n",
       "      <td>2_mp4_trial_2.json</td>\n",
       "      <td>Said though, that if you did run for president...</td>\n",
       "      <td>2</td>\n",
       "      <td>video2.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://www.tiktok.com/@bwtgrils_/video/736257...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah.'</td>\n",
       "      <td>3_mp4_trial_2.json</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>3</td>\n",
       "      <td>video3.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                               Link  Label  \\\n",
       "0    1.0  https://www.tiktok.com/@1tashyat/video/7359361...      1   \n",
       "1    2.0  https://www.tiktok.com/@monkeman317/video/7357...      1   \n",
       "2    3.0  https://www.tiktok.com/@bwtgrils_/video/736257...      1   \n",
       "\n",
       "                                                Text            FileName  \\\n",
       "0  \"ST Anselm College. She's a Republican. This w...  1_mp4_trial_2.json   \n",
       "1  \"Said though, that if you did run for presiden...  2_mp4_trial_2.json   \n",
       "2                                             Yeah.'  3_mp4_trial_2.json   \n",
       "\n",
       "                                       Transcription  sort_key  Video Name  \n",
       "0  ST Anselm College. She's a Republican. This wi...         1  video1.mp4  \n",
       "1  Said though, that if you did run for president...         2  video2.mp4  \n",
       "2                                              Yeah.         3  video3.mp4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Video Name'] = df['Index'].apply(lambda x: f'video{int(x)}.mp4')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a900c42a-8a2c-4a06-a2e2-6070f3776266",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'path/to/videos/'\n",
    "video_paths = df['Video Name'].apply(lambda x: base_dir + x).tolist()\n",
    "labels = df['Label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ee3de-09f8-4b9e-936a-1c396fb13726",
   "metadata": {},
   "source": [
    "# Download Train/Test Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "532f2a9c-61b3-466f-afa7-5ba14be8a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video20.mp4 to train_video_796.mp4\n",
      "Downloading video102.mp4 to train_video_101.mp4\n",
      "Downloading video20.mp4 to train_video_798.mp4\n",
      "Downloading video531.mp4 to train_video_530.mp4\n",
      "Downloading video431.mp4 to train_video_430.mp4\n",
      "Downloading video445.mp4 to train_video_444.mp4\n",
      "Downloading video3.mp4 to train_video_2.mp4\n",
      "Downloading video193.mp4 to train_video_192.mp4\n",
      "Downloading video463.mp4 to train_video_462.mp4\n",
      "Downloading video498.mp4 to train_video_497.mp4\n",
      "Downloading video434.mp4 to train_video_433.mp4\n",
      "Downloading video20.mp4 to train_video_771.mp4\n",
      "Downloading video486.mp4 to train_video_485.mp4\n",
      "Downloading video20.mp4 to train_video_805.mp4\n",
      "Downloading video545.mp4 to train_video_544.mp4\n",
      "Downloading video332.mp4 to train_video_331.mp4\n",
      "Downloading video502.mp4 to train_video_501.mp4\n",
      "Downloading video20.mp4 to train_video_578.mp4\n",
      "Downloading video494.mp4 to train_video_493.mp4\n",
      "Downloading video451.mp4 to train_video_450.mp4\n",
      "Downloading video369.mp4 to train_video_368.mp4\n",
      "Downloading video20.mp4 to train_video_612.mp4\n",
      "Downloading video80.mp4 to train_video_79.mp4\n",
      "Downloading video149.mp4 to train_video_148.mp4\n",
      "Downloading video394.mp4 to train_video_393.mp4\n",
      "Downloading video219.mp4 to train_video_218.mp4\n",
      "Downloading video20.mp4 to train_video_809.mp4\n",
      "Downloading video362.mp4 to train_video_361.mp4\n",
      "Downloading video353.mp4 to train_video_352.mp4\n",
      "Downloading video20.mp4 to train_video_687.mp4\n",
      "Downloading video310.mp4 to train_video_309.mp4\n",
      "Downloading video134.mp4 to train_video_133.mp4\n",
      "Downloading video429.mp4 to train_video_428.mp4\n",
      "Downloading video255.mp4 to train_video_254.mp4\n",
      "Downloading video524.mp4 to train_video_523.mp4\n",
      "Downloading video56.mp4 to train_video_55.mp4\n",
      "Downloading video508.mp4 to train_video_507.mp4\n",
      "Downloading video20.mp4 to train_video_695.mp4\n",
      "Downloading video526.mp4 to train_video_525.mp4\n",
      "Downloading video20.mp4 to train_video_748.mp4\n",
      "Downloading video433.mp4 to train_video_432.mp4\n",
      "Downloading video205.mp4 to train_video_204.mp4\n",
      "Downloading video20.mp4 to train_video_596.mp4\n",
      "Downloading video20.mp4 to train_video_591.mp4\n",
      "Downloading video307.mp4 to train_video_306.mp4\n",
      "Downloading video333.mp4 to train_video_332.mp4\n",
      "Downloading video426.mp4 to train_video_425.mp4\n",
      "Downloading video61.mp4 to train_video_60.mp4\n",
      "Downloading video200.mp4 to train_video_199.mp4\n",
      "Downloading video20.mp4 to train_video_648.mp4\n",
      "Downloading video20.mp4 to train_video_618.mp4\n",
      "Downloading video20.mp4 to train_video_590.mp4\n",
      "Downloading video430.mp4 to train_video_429.mp4\n",
      "Downloading video446.mp4 to train_video_445.mp4\n",
      "Downloading video20.mp4 to train_video_610.mp4\n",
      "Downloading video495.mp4 to train_video_494.mp4\n",
      "Downloading video20.mp4 to train_video_651.mp4\n",
      "Downloading video20.mp4 to train_video_642.mp4\n",
      "Downloading video20.mp4 to train_video_769.mp4\n",
      "Downloading video20.mp4 to train_video_624.mp4\n",
      "Downloading video335.mp4 to train_video_334.mp4\n",
      "Downloading video20.mp4 to train_video_842.mp4\n",
      "Downloading video91.mp4 to train_video_90.mp4\n",
      "Downloading video20.mp4 to train_video_810.mp4\n",
      "Downloading video182.mp4 to train_video_181.mp4\n",
      "Downloading video457.mp4 to train_video_456.mp4\n",
      "Downloading video501.mp4 to train_video_500.mp4\n",
      "Downloading video20.mp4 to train_video_754.mp4\n",
      "Downloading video159.mp4 to train_video_158.mp4\n",
      "Downloading video70.mp4 to train_video_69.mp4\n",
      "Downloading video320.mp4 to train_video_319.mp4\n",
      "Downloading video132.mp4 to train_video_131.mp4\n",
      "Downloading video45.mp4 to train_video_44.mp4\n",
      "Downloading video20.mp4 to train_video_605.mp4\n",
      "Downloading video71.mp4 to train_video_70.mp4\n",
      "Downloading video437.mp4 to train_video_436.mp4\n",
      "Downloading video20.mp4 to train_video_816.mp4\n",
      "Downloading video399.mp4 to train_video_398.mp4\n",
      "Downloading video352.mp4 to train_video_351.mp4\n",
      "Downloading video20.mp4 to train_video_562.mp4\n",
      "Downloading video240.mp4 to train_video_239.mp4\n",
      "Downloading video136.mp4 to train_video_135.mp4\n",
      "Downloading video83.mp4 to train_video_82.mp4\n",
      "Downloading video166.mp4 to train_video_165.mp4\n",
      "Downloading video165.mp4 to train_video_164.mp4\n",
      "Downloading video29.mp4 to train_video_28.mp4\n",
      "Downloading video20.mp4 to train_video_675.mp4\n",
      "Downloading video194.mp4 to train_video_193.mp4\n",
      "Downloading video405.mp4 to train_video_404.mp4\n",
      "Downloading video466.mp4 to train_video_465.mp4\n",
      "Downloading video351.mp4 to train_video_350.mp4\n",
      "Downloading video141.mp4 to train_video_140.mp4\n",
      "Downloading video174.mp4 to train_video_173.mp4\n",
      "Downloading video7.mp4 to train_video_6.mp4\n",
      "Downloading video20.mp4 to train_video_565.mp4\n",
      "Downloading video343.mp4 to train_video_342.mp4\n",
      "Downloading video74.mp4 to train_video_73.mp4\n",
      "Downloading video20.mp4 to train_video_747.mp4\n",
      "Downloading video20.mp4 to train_video_611.mp4\n",
      "Downloading video20.mp4 to train_video_744.mp4\n",
      "Downloading video146.mp4 to train_video_145.mp4\n",
      "Downloading video235.mp4 to train_video_234.mp4\n",
      "Downloading video221.mp4 to train_video_220.mp4\n",
      "Downloading video361.mp4 to train_video_360.mp4\n",
      "Downloading video358.mp4 to train_video_357.mp4\n",
      "Downloading video133.mp4 to train_video_132.mp4\n",
      "Downloading video421.mp4 to train_video_420.mp4\n",
      "Downloading video20.mp4 to train_video_678.mp4\n",
      "Downloading video20.mp4 to train_video_823.mp4\n",
      "Downloading video42.mp4 to train_video_41.mp4\n",
      "Downloading video529.mp4 to train_video_528.mp4\n",
      "Downloading video109.mp4 to train_video_108.mp4\n",
      "Downloading video20.mp4 to train_video_789.mp4\n",
      "Downloading video57.mp4 to train_video_56.mp4\n",
      "Downloading video292.mp4 to train_video_291.mp4\n",
      "Downloading video317.mp4 to train_video_316.mp4\n",
      "Downloading video20.mp4 to train_video_850.mp4\n",
      "Downloading video25.mp4 to train_video_24.mp4\n",
      "Downloading video20.mp4 to train_video_760.mp4\n",
      "Downloading video395.mp4 to train_video_394.mp4\n",
      "Downloading video491.mp4 to train_video_490.mp4\n",
      "Downloading video52.mp4 to train_video_51.mp4\n",
      "Downloading video20.mp4 to train_video_844.mp4\n",
      "Downloading video20.mp4 to train_video_792.mp4\n",
      "Downloading video20.mp4 to train_video_629.mp4\n",
      "Downloading video265.mp4 to train_video_264.mp4\n",
      "Downloading video20.mp4 to train_video_781.mp4\n",
      "Downloading video20.mp4 to train_video_599.mp4\n",
      "Downloading video20.mp4 to train_video_681.mp4\n",
      "Downloading video483.mp4 to train_video_482.mp4\n",
      "Downloading video19.mp4 to train_video_18.mp4\n",
      "Downloading video20.mp4 to train_video_626.mp4\n",
      "Downloading video20.mp4 to train_video_843.mp4\n",
      "Downloading video84.mp4 to train_video_83.mp4\n",
      "Downloading video62.mp4 to train_video_61.mp4\n",
      "Downloading video273.mp4 to train_video_272.mp4\n",
      "Downloading video286.mp4 to train_video_285.mp4\n",
      "Downloading video328.mp4 to train_video_327.mp4\n",
      "Downloading video427.mp4 to train_video_426.mp4\n",
      "Downloading video500.mp4 to train_video_499.mp4\n",
      "Downloading video183.mp4 to train_video_182.mp4\n",
      "Downloading video484.mp4 to train_video_483.mp4\n",
      "Downloading video534.mp4 to train_video_533.mp4\n",
      "Downloading video224.mp4 to train_video_223.mp4\n",
      "Downloading video474.mp4 to train_video_473.mp4\n",
      "Downloading video20.mp4 to train_video_613.mp4\n",
      "Downloading video360.mp4 to train_video_359.mp4\n",
      "Downloading video488.mp4 to train_video_487.mp4\n",
      "Downloading video496.mp4 to train_video_495.mp4\n",
      "Downloading video528.mp4 to train_video_527.mp4\n",
      "Downloading video177.mp4 to train_video_176.mp4\n",
      "Downloading video20.mp4 to train_video_587.mp4\n",
      "Downloading video20.mp4 to train_video_770.mp4\n",
      "Downloading video164.mp4 to train_video_163.mp4\n",
      "Downloading video249.mp4 to train_video_248.mp4\n",
      "Downloading video20.mp4 to train_video_559.mp4\n",
      "Downloading video20.mp4 to train_video_763.mp4\n",
      "Downloading video75.mp4 to train_video_74.mp4\n",
      "Downloading video114.mp4 to train_video_113.mp4\n",
      "Downloading video487.mp4 to train_video_486.mp4\n",
      "Downloading video454.mp4 to train_video_453.mp4\n",
      "Downloading video105.mp4 to train_video_104.mp4\n",
      "Downloading video115.mp4 to train_video_114.mp4\n",
      "Downloading video20.mp4 to train_video_696.mp4\n",
      "Downloading video93.mp4 to train_video_92.mp4\n",
      "Downloading video20.mp4 to train_video_633.mp4\n",
      "Downloading video90.mp4 to train_video_89.mp4\n",
      "Downloading video337.mp4 to train_video_336.mp4\n",
      "Downloading video550.mp4 to train_video_549.mp4\n",
      "Downloading video20.mp4 to train_video_793.mp4\n",
      "Downloading video20.mp4 to train_video_804.mp4\n",
      "Downloading video20.mp4 to train_video_703.mp4\n",
      "Downloading video530.mp4 to train_video_529.mp4\n",
      "Downloading video95.mp4 to train_video_94.mp4\n",
      "Downloading video12.mp4 to train_video_11.mp4\n",
      "Downloading video397.mp4 to train_video_396.mp4\n",
      "Downloading video44.mp4 to train_video_43.mp4\n",
      "Downloading video43.mp4 to train_video_42.mp4\n",
      "Downloading video330.mp4 to train_video_329.mp4\n",
      "Downloading video168.mp4 to train_video_167.mp4\n",
      "Downloading video20.mp4 to train_video_766.mp4\n",
      "Downloading video519.mp4 to train_video_518.mp4\n",
      "Downloading video20.mp4 to train_video_661.mp4\n",
      "Downloading video20.mp4 to train_video_716.mp4\n",
      "Downloading video179.mp4 to train_video_178.mp4\n",
      "Downloading video20.mp4 to train_video_822.mp4\n",
      "Downloading video20.mp4 to train_video_580.mp4\n",
      "Downloading video178.mp4 to train_video_177.mp4\n",
      "Downloading video20.mp4 to train_video_594.mp4\n",
      "Downloading video20.mp4 to train_video_729.mp4\n",
      "Downloading video20.mp4 to train_video_601.mp4\n",
      "Downloading video258.mp4 to train_video_257.mp4\n",
      "Downloading video20.mp4 to train_video_855.mp4\n",
      "Downloading video336.mp4 to train_video_335.mp4\n",
      "Downloading video533.mp4 to train_video_532.mp4\n",
      "Downloading video16.mp4 to train_video_15.mp4\n",
      "Downloading video4.mp4 to train_video_3.mp4\n",
      "Downloading video378.mp4 to train_video_377.mp4\n",
      "Downloading video257.mp4 to train_video_256.mp4\n",
      "Downloading video417.mp4 to train_video_416.mp4\n",
      "Downloading video20.mp4 to train_video_692.mp4\n",
      "Downloading video381.mp4 to train_video_380.mp4\n",
      "Downloading video223.mp4 to train_video_222.mp4\n",
      "Downloading video20.mp4 to train_video_853.mp4\n",
      "Downloading video418.mp4 to train_video_417.mp4\n",
      "Downloading video20.mp4 to train_video_658.mp4\n",
      "Downloading video325.mp4 to train_video_324.mp4\n",
      "Downloading video20.mp4 to train_video_673.mp4\n",
      "Downloading video10.mp4 to train_video_9.mp4\n",
      "Downloading video250.mp4 to train_video_249.mp4\n",
      "Downloading video23.mp4 to train_video_22.mp4\n",
      "Downloading video357.mp4 to train_video_356.mp4\n",
      "Downloading video222.mp4 to train_video_221.mp4\n",
      "Downloading video20.mp4 to train_video_588.mp4\n",
      "Downloading video20.mp4 to train_video_743.mp4\n",
      "Downloading video20.mp4 to train_video_847.mp4\n",
      "Downloading video20.mp4 to train_video_795.mp4\n",
      "Downloading video341.mp4 to train_video_340.mp4\n",
      "Downloading video20.mp4 to train_video_723.mp4\n",
      "Downloading video204.mp4 to train_video_203.mp4\n",
      "Downloading video238.mp4 to train_video_237.mp4\n",
      "Downloading video94.mp4 to train_video_93.mp4\n",
      "Downloading video449.mp4 to train_video_448.mp4\n",
      "Downloading video406.mp4 to train_video_405.mp4\n",
      "Downloading video20.mp4 to train_video_705.mp4\n",
      "Downloading video285.mp4 to train_video_284.mp4\n",
      "Downloading video185.mp4 to train_video_184.mp4\n",
      "Downloading video20.mp4 to train_video_700.mp4\n",
      "Downloading video20.mp4 to train_video_726.mp4\n",
      "Downloading video154.mp4 to train_video_153.mp4\n",
      "Downloading video76.mp4 to train_video_75.mp4\n",
      "Downloading video20.mp4 to train_video_688.mp4\n",
      "Downloading video532.mp4 to train_video_531.mp4\n",
      "Downloading video278.mp4 to train_video_277.mp4\n",
      "Downloading video69.mp4 to train_video_68.mp4\n",
      "Downloading video546.mp4 to train_video_545.mp4\n",
      "Downloading video189.mp4 to train_video_188.mp4\n",
      "Downloading video272.mp4 to train_video_271.mp4\n",
      "Downloading video20.mp4 to train_video_715.mp4\n",
      "Downloading video537.mp4 to train_video_536.mp4\n",
      "Downloading video237.mp4 to train_video_236.mp4\n",
      "Downloading video89.mp4 to train_video_88.mp4\n",
      "Downloading video20.mp4 to train_video_772.mp4\n",
      "Downloading video118.mp4 to train_video_117.mp4\n",
      "Downloading video126.mp4 to train_video_125.mp4\n",
      "Downloading video20.mp4 to train_video_711.mp4\n",
      "Downloading video290.mp4 to train_video_289.mp4\n",
      "Downloading video239.mp4 to train_video_238.mp4\n",
      "Downloading video1.mp4 to train_video_0.mp4\n",
      "Downloading video20.mp4 to train_video_854.mp4\n",
      "Downloading video432.mp4 to train_video_431.mp4\n",
      "Downloading video20.mp4 to train_video_753.mp4\n",
      "Downloading video396.mp4 to train_video_395.mp4\n",
      "Downloading video513.mp4 to train_video_512.mp4\n",
      "Downloading video127.mp4 to train_video_126.mp4\n",
      "Downloading video279.mp4 to train_video_278.mp4\n",
      "Downloading video20.mp4 to train_video_672.mp4\n",
      "Downloading video117.mp4 to train_video_116.mp4\n",
      "Downloading video229.mp4 to train_video_228.mp4\n",
      "Downloading video20.mp4 to train_video_807.mp4\n",
      "Downloading video20.mp4 to train_video_821.mp4\n",
      "Downloading video20.mp4 to train_video_782.mp4\n",
      "Downloading video275.mp4 to train_video_274.mp4\n",
      "Downloading video319.mp4 to train_video_318.mp4\n",
      "Downloading video20.mp4 to train_video_592.mp4\n",
      "Downloading video145.mp4 to train_video_144.mp4\n",
      "Downloading video20.mp4 to train_video_619.mp4\n",
      "Downloading video540.mp4 to train_video_539.mp4\n",
      "Downloading video20.mp4 to train_video_785.mp4\n",
      "Downloading video20.mp4 to train_video_693.mp4\n",
      "Downloading video370.mp4 to train_video_369.mp4\n",
      "Downloading video269.mp4 to train_video_268.mp4\n",
      "Downloading video20.mp4 to train_video_609.mp4\n",
      "Downloading video308.mp4 to train_video_307.mp4\n",
      "Downloading video424.mp4 to train_video_423.mp4\n",
      "Downloading video311.mp4 to train_video_310.mp4\n",
      "Downloading video20.mp4 to train_video_576.mp4\n",
      "Downloading video47.mp4 to train_video_46.mp4\n",
      "Downloading video350.mp4 to train_video_349.mp4\n",
      "Downloading video372.mp4 to train_video_371.mp4\n",
      "Downloading video20.mp4 to train_video_697.mp4\n",
      "Downloading video262.mp4 to train_video_261.mp4\n",
      "Downloading video196.mp4 to train_video_195.mp4\n",
      "Downloading video20.mp4 to train_video_862.mp4\n",
      "Downloading video20.mp4 to train_video_724.mp4\n",
      "Downloading video108.mp4 to train_video_107.mp4\n",
      "Downloading video60.mp4 to train_video_59.mp4\n",
      "Downloading video20.mp4 to train_video_643.mp4\n",
      "Downloading video20.mp4 to train_video_840.mp4\n",
      "Downloading video101.mp4 to train_video_100.mp4\n",
      "Downloading video444.mp4 to train_video_443.mp4\n",
      "Downloading video20.mp4 to train_video_593.mp4\n",
      "Downloading video20.mp4 to train_video_775.mp4\n",
      "Downloading video20.mp4 to train_video_625.mp4\n",
      "Downloading video507.mp4 to train_video_506.mp4\n",
      "Downloading video180.mp4 to train_video_179.mp4\n",
      "Downloading video305.mp4 to train_video_304.mp4\n",
      "Downloading video479.mp4 to train_video_478.mp4\n",
      "Downloading video58.mp4 to train_video_57.mp4\n",
      "Downloading video20.mp4 to train_video_832.mp4\n",
      "Downloading video150.mp4 to train_video_149.mp4\n",
      "Downloading video125.mp4 to train_video_124.mp4\n",
      "Downloading video20.mp4 to train_video_684.mp4\n",
      "Downloading video20.mp4 to train_video_750.mp4\n",
      "Downloading video186.mp4 to train_video_185.mp4\n",
      "Downloading video20.mp4 to train_video_714.mp4\n",
      "Downloading video51.mp4 to train_video_50.mp4\n",
      "Downloading video342.mp4 to train_video_341.mp4\n",
      "Downloading video447.mp4 to train_video_446.mp4\n",
      "Downloading video20.mp4 to train_video_852.mp4\n",
      "Downloading video536.mp4 to train_video_535.mp4\n",
      "Downloading video322.mp4 to train_video_321.mp4\n",
      "Downloading video354.mp4 to train_video_353.mp4\n",
      "Downloading video20.mp4 to train_video_799.mp4\n",
      "Downloading video143.mp4 to train_video_142.mp4\n",
      "Downloading video471.mp4 to train_video_470.mp4\n",
      "Downloading video371.mp4 to train_video_370.mp4\n",
      "Downloading video20.mp4 to train_video_818.mp4\n",
      "Downloading video142.mp4 to train_video_141.mp4\n",
      "Downloading video400.mp4 to train_video_399.mp4\n",
      "Downloading video264.mp4 to train_video_263.mp4\n",
      "Downloading video321.mp4 to train_video_320.mp4\n",
      "Downloading video20.mp4 to train_video_19.mp4\n",
      "Downloading video173.mp4 to train_video_172.mp4\n",
      "Downloading video20.mp4 to train_video_704.mp4\n",
      "Downloading video313.mp4 to train_video_312.mp4\n",
      "Downloading video391.mp4 to train_video_390.mp4\n",
      "Downloading video20.mp4 to train_video_806.mp4\n",
      "Downloading video13.mp4 to train_video_12.mp4\n",
      "Downloading video408.mp4 to train_video_407.mp4\n",
      "Downloading video409.mp4 to train_video_408.mp4\n",
      "Downloading video306.mp4 to train_video_305.mp4\n",
      "Downloading video355.mp4 to train_video_354.mp4\n",
      "Downloading video26.mp4 to train_video_25.mp4\n",
      "Downloading video20.mp4 to train_video_641.mp4\n",
      "Downloading video170.mp4 to train_video_169.mp4\n",
      "Downloading video539.mp4 to train_video_538.mp4\n",
      "Downloading video39.mp4 to train_video_38.mp4\n",
      "Downloading video176.mp4 to train_video_175.mp4\n",
      "Downloading video246.mp4 to train_video_245.mp4\n",
      "Downloading video299.mp4 to train_video_298.mp4\n",
      "Downloading video20.mp4 to train_video_720.mp4\n",
      "Downloading video20.mp4 to train_video_589.mp4\n",
      "Downloading video20.mp4 to train_video_659.mp4\n",
      "Downloading video20.mp4 to train_video_741.mp4\n",
      "Downloading video155.mp4 to train_video_154.mp4\n",
      "Downloading video288.mp4 to train_video_287.mp4\n",
      "Downloading video522.mp4 to train_video_521.mp4\n",
      "Downloading video18.mp4 to train_video_17.mp4\n",
      "Downloading video128.mp4 to train_video_127.mp4\n",
      "Downloading video323.mp4 to train_video_322.mp4\n",
      "Downloading video256.mp4 to train_video_255.mp4\n",
      "Downloading video20.mp4 to train_video_607.mp4\n",
      "Downloading video20.mp4 to train_video_830.mp4\n",
      "Downloading video191.mp4 to train_video_190.mp4\n",
      "Downloading video116.mp4 to train_video_115.mp4\n",
      "Downloading video535.mp4 to train_video_534.mp4\n",
      "Downloading video181.mp4 to train_video_180.mp4\n",
      "Downloading video302.mp4 to train_video_301.mp4\n",
      "Downloading video20.mp4 to train_video_664.mp4\n",
      "Downloading video20.mp4 to train_video_623.mp4\n",
      "Downloading video20.mp4 to train_video_634.mp4\n",
      "Downloading video20.mp4 to train_video_602.mp4\n",
      "Downloading video20.mp4 to train_video_583.mp4\n",
      "Downloading video518.mp4 to train_video_517.mp4\n",
      "Downloading video20.mp4 to train_video_848.mp4\n",
      "Downloading video46.mp4 to train_video_45.mp4\n",
      "Downloading video20.mp4 to train_video_794.mp4\n",
      "Downloading video158.mp4 to train_video_157.mp4\n",
      "Downloading video20.mp4 to train_video_725.mp4\n",
      "Downloading video172.mp4 to train_video_171.mp4\n",
      "Downloading video17.mp4 to train_video_16.mp4\n",
      "Downloading video512.mp4 to train_video_511.mp4\n",
      "Downloading video49.mp4 to train_video_48.mp4\n",
      "Downloading video20.mp4 to train_video_836.mp4\n",
      "Downloading video20.mp4 to train_video_728.mp4\n",
      "Downloading video516.mp4 to train_video_515.mp4\n",
      "Downloading video20.mp4 to train_video_603.mp4\n",
      "Downloading video481.mp4 to train_video_480.mp4\n",
      "Downloading video284.mp4 to train_video_283.mp4\n",
      "Downloading video20.mp4 to train_video_577.mp4\n",
      "Downloading video226.mp4 to train_video_225.mp4\n",
      "Downloading video27.mp4 to train_video_26.mp4\n",
      "Downloading video20.mp4 to train_video_680.mp4\n",
      "Downloading video438.mp4 to train_video_437.mp4\n",
      "Downloading video365.mp4 to train_video_364.mp4\n",
      "Downloading video230.mp4 to train_video_229.mp4\n",
      "Downloading video38.mp4 to train_video_37.mp4\n",
      "Downloading video20.mp4 to train_video_831.mp4\n",
      "Downloading video375.mp4 to train_video_374.mp4\n",
      "Downloading video470.mp4 to train_video_469.mp4\n",
      "Downloading video20.mp4 to train_video_833.mp4\n",
      "Downloading video20.mp4 to train_video_735.mp4\n",
      "Downloading video20.mp4 to train_video_636.mp4\n",
      "Downloading video195.mp4 to train_video_194.mp4\n",
      "Downloading video20.mp4 to train_video_780.mp4\n",
      "Downloading video20.mp4 to train_video_746.mp4\n",
      "Downloading video504.mp4 to train_video_503.mp4\n",
      "Downloading video20.mp4 to train_video_835.mp4\n",
      "Downloading video20.mp4 to train_video_721.mp4\n",
      "Downloading video20.mp4 to train_video_834.mp4\n",
      "Downloading video163.mp4 to train_video_162.mp4\n",
      "Downloading video20.mp4 to train_video_668.mp4\n",
      "Downloading video153.mp4 to train_video_152.mp4\n",
      "Downloading video20.mp4 to train_video_598.mp4\n",
      "Downloading video20.mp4 to train_video_614.mp4\n",
      "Downloading video20.mp4 to train_video_660.mp4\n",
      "Downloading video112.mp4 to train_video_111.mp4\n",
      "Downloading video227.mp4 to train_video_226.mp4\n",
      "Downloading video20.mp4 to train_video_604.mp4\n",
      "Downloading video104.mp4 to train_video_103.mp4\n",
      "Downloading video422.mp4 to train_video_421.mp4\n",
      "Downloading video420.mp4 to train_video_419.mp4\n",
      "Downloading video120.mp4 to train_video_119.mp4\n",
      "Downloading video54.mp4 to train_video_53.mp4\n",
      "Downloading video152.mp4 to train_video_151.mp4\n",
      "Downloading video404.mp4 to train_video_403.mp4\n",
      "Downloading video20.mp4 to train_video_814.mp4\n",
      "Downloading video208.mp4 to train_video_207.mp4\n",
      "Downloading video20.mp4 to train_video_730.mp4\n",
      "Downloading video20.mp4 to train_video_666.mp4\n",
      "Downloading video9.mp4 to train_video_8.mp4\n",
      "Downloading video20.mp4 to train_video_702.mp4\n",
      "Downloading video37.mp4 to train_video_36.mp4\n",
      "Downloading video453.mp4 to train_video_452.mp4\n",
      "Downloading video254.mp4 to train_video_253.mp4\n",
      "Downloading video304.mp4 to train_video_303.mp4\n",
      "Downloading video20.mp4 to train_video_652.mp4\n",
      "Downloading video20.mp4 to train_video_579.mp4\n",
      "Downloading video20.mp4 to train_video_621.mp4\n",
      "Downloading video20.mp4 to train_video_630.mp4\n",
      "Downloading video263.mp4 to train_video_262.mp4\n",
      "Downloading video298.mp4 to train_video_297.mp4\n",
      "Downloading video415.mp4 to train_video_414.mp4\n",
      "Downloading video151.mp4 to train_video_150.mp4\n",
      "Downloading video20.mp4 to train_video_686.mp4\n",
      "Downloading video20.mp4 to train_video_765.mp4\n",
      "Downloading video20.mp4 to train_video_558.mp4\n",
      "Downloading video489.mp4 to train_video_488.mp4\n",
      "Downloading video148.mp4 to train_video_147.mp4\n",
      "Downloading video147.mp4 to train_video_146.mp4\n",
      "Downloading video20.mp4 to train_video_631.mp4\n",
      "Downloading video20.mp4 to train_video_802.mp4\n",
      "Downloading video20.mp4 to train_video_646.mp4\n",
      "Downloading video349.mp4 to train_video_348.mp4\n",
      "Downloading video464.mp4 to train_video_463.mp4\n",
      "Downloading video326.mp4 to train_video_325.mp4\n",
      "Downloading video187.mp4 to train_video_186.mp4\n",
      "Downloading video124.mp4 to train_video_123.mp4\n",
      "Downloading video20.mp4 to train_video_736.mp4\n",
      "Downloading video20.mp4 to train_video_616.mp4\n",
      "Downloading video144.mp4 to train_video_143.mp4\n",
      "Downloading video20.mp4 to train_video_825.mp4\n",
      "Downloading video198.mp4 to train_video_197.mp4\n",
      "Downloading video20.mp4 to train_video_617.mp4\n",
      "Downloading video280.mp4 to train_video_279.mp4\n",
      "Downloading video294.mp4 to train_video_293.mp4\n",
      "Downloading video401.mp4 to train_video_400.mp4\n",
      "Downloading video123.mp4 to train_video_122.mp4\n",
      "Downloading video184.mp4 to train_video_183.mp4\n",
      "Downloading video203.mp4 to train_video_202.mp4\n",
      "Downloading video439.mp4 to train_video_438.mp4\n",
      "Downloading video247.mp4 to train_video_246.mp4\n",
      "Downloading video416.mp4 to train_video_415.mp4\n",
      "Downloading video20.mp4 to train_video_764.mp4\n",
      "Downloading video130.mp4 to train_video_129.mp4\n",
      "Downloading video20.mp4 to train_video_645.mp4\n",
      "Downloading video403.mp4 to train_video_402.mp4\n",
      "Downloading video20.mp4 to train_video_745.mp4\n",
      "Downloading video20.mp4 to train_video_846.mp4\n",
      "Downloading video20.mp4 to train_video_786.mp4\n",
      "Downloading video220.mp4 to train_video_219.mp4\n",
      "Downloading video20.mp4 to train_video_649.mp4\n",
      "Downloading video20.mp4 to train_video_788.mp4\n",
      "Downloading video20.mp4 to train_video_657.mp4\n",
      "Downloading video20.mp4 to train_video_791.mp4\n",
      "Downloading video20.mp4 to train_video_632.mp4\n",
      "Downloading video20.mp4 to train_video_767.mp4\n",
      "Downloading video20.mp4 to train_video_665.mp4\n",
      "Downloading video387.mp4 to train_video_386.mp4\n",
      "Downloading video20.mp4 to train_video_837.mp4\n",
      "Downloading video510.mp4 to train_video_509.mp4\n",
      "Downloading video268.mp4 to train_video_267.mp4\n",
      "Downloading video20.mp4 to train_video_712.mp4\n",
      "Downloading video442.mp4 to train_video_441.mp4\n",
      "Downloading video497.mp4 to train_video_496.mp4\n",
      "Downloading video113.mp4 to train_video_112.mp4\n",
      "Downloading video233.mp4 to train_video_232.mp4\n",
      "Downloading video20.mp4 to train_video_751.mp4\n",
      "Downloading video20.mp4 to train_video_615.mp4\n",
      "Downloading video374.mp4 to train_video_373.mp4\n",
      "Downloading video234.mp4 to train_video_233.mp4\n",
      "Downloading video20.mp4 to train_video_683.mp4\n",
      "Downloading video318.mp4 to train_video_317.mp4\n",
      "Downloading video20.mp4 to train_video_656.mp4\n",
      "Downloading video411.mp4 to train_video_410.mp4\n",
      "Downloading video20.mp4 to train_video_774.mp4\n",
      "Downloading video359.mp4 to train_video_358.mp4\n",
      "Downloading video259.mp4 to train_video_258.mp4\n",
      "Downloading video20.mp4 to train_video_635.mp4\n",
      "Downloading video20.mp4 to train_video_640.mp4\n",
      "Downloading video283.mp4 to train_video_282.mp4\n",
      "Downloading video377.mp4 to train_video_376.mp4\n",
      "Downloading video385.mp4 to train_video_384.mp4\n",
      "Downloading video225.mp4 to train_video_224.mp4\n",
      "Downloading video20.mp4 to train_video_820.mp4\n",
      "Downloading video20.mp4 to train_video_857.mp4\n",
      "Downloading video473.mp4 to train_video_472.mp4\n",
      "Downloading video348.mp4 to train_video_347.mp4\n",
      "Downloading video506.mp4 to train_video_505.mp4\n",
      "Downloading video20.mp4 to train_video_647.mp4\n",
      "Downloading video20.mp4 to train_video_851.mp4\n",
      "Downloading video20.mp4 to train_video_800.mp4\n",
      "Downloading video20.mp4 to train_video_803.mp4\n",
      "Downloading video20.mp4 to train_video_627.mp4\n",
      "Downloading video20.mp4 to train_video_738.mp4\n",
      "Downloading video20.mp4 to train_video_653.mp4\n",
      "Downloading video20.mp4 to train_video_731.mp4\n",
      "Downloading video20.mp4 to train_video_564.mp4\n",
      "Downloading video20.mp4 to train_video_824.mp4\n",
      "Downloading video20.mp4 to train_video_585.mp4\n",
      "Downloading video86.mp4 to train_video_85.mp4\n",
      "Downloading video243.mp4 to train_video_242.mp4\n",
      "Downloading video160.mp4 to train_video_159.mp4\n",
      "Downloading video525.mp4 to train_video_524.mp4\n",
      "Downloading video36.mp4 to train_video_35.mp4\n",
      "Downloading video541.mp4 to train_video_540.mp4\n",
      "Downloading video171.mp4 to train_video_170.mp4\n",
      "Downloading video20.mp4 to train_video_662.mp4\n",
      "Downloading video20.mp4 to train_video_740.mp4\n",
      "Downloading video20.mp4 to train_video_768.mp4\n",
      "Downloading video20.mp4 to train_video_838.mp4\n",
      "Downloading video96.mp4 to train_video_95.mp4\n",
      "Downloading video20.mp4 to train_video_571.mp4\n",
      "Downloading video241.mp4 to train_video_240.mp4\n",
      "Downloading video20.mp4 to train_video_582.mp4\n",
      "Downloading video20.mp4 to train_video_698.mp4\n",
      "Downloading video461.mp4 to train_video_460.mp4\n",
      "Downloading video20.mp4 to train_video_561.mp4\n",
      "Downloading video20.mp4 to train_video_757.mp4\n",
      "Downloading video207.mp4 to train_video_206.mp4\n",
      "Downloading video393.mp4 to train_video_392.mp4\n",
      "Downloading video398.mp4 to train_video_397.mp4\n",
      "Downloading video20.mp4 to train_video_733.mp4\n",
      "Downloading video218.mp4 to train_video_217.mp4\n",
      "Downloading video5.mp4 to train_video_4.mp4\n",
      "Downloading video20.mp4 to train_video_650.mp4\n",
      "Downloading video20.mp4 to train_video_773.mp4\n",
      "Downloading video20.mp4 to train_video_620.mp4\n",
      "Downloading video547.mp4 to train_video_546.mp4\n",
      "Downloading video20.mp4 to train_video_691.mp4\n",
      "Downloading video99.mp4 to train_video_98.mp4\n",
      "Downloading video20.mp4 to train_video_581.mp4\n",
      "Downloading video407.mp4 to train_video_406.mp4\n",
      "Downloading video503.mp4 to train_video_502.mp4\n",
      "Downloading video48.mp4 to train_video_47.mp4\n",
      "Downloading video33.mp4 to train_video_32.mp4\n",
      "Downloading video201.mp4 to train_video_200.mp4\n",
      "Downloading video135.mp4 to train_video_134.mp4\n",
      "Downloading video28.mp4 to train_video_27.mp4\n",
      "Downloading video20.mp4 to train_video_759.mp4\n",
      "Downloading video231.mp4 to train_video_230.mp4\n",
      "Downloading video490.mp4 to train_video_489.mp4\n",
      "Downloading video379.mp4 to train_video_378.mp4\n",
      "Downloading video289.mp4 to train_video_288.mp4\n",
      "Downloading video419.mp4 to train_video_418.mp4\n",
      "Downloading video20.mp4 to train_video_682.mp4\n",
      "Downloading video392.mp4 to train_video_391.mp4\n",
      "Downloading video20.mp4 to train_video_600.mp4\n",
      "Downloading video499.mp4 to train_video_498.mp4\n",
      "Downloading video139.mp4 to train_video_138.mp4\n",
      "Downloading video63.mp4 to train_video_62.mp4\n",
      "Downloading video472.mp4 to train_video_471.mp4\n",
      "Downloading video20.mp4 to train_video_655.mp4\n",
      "Downloading video129.mp4 to train_video_128.mp4\n",
      "Downloading video20.mp4 to train_video_841.mp4\n",
      "Downloading video521.mp4 to train_video_520.mp4\n",
      "Downloading video65.mp4 to train_video_64.mp4\n",
      "Downloading video15.mp4 to train_video_14.mp4\n",
      "Downloading video157.mp4 to train_video_156.mp4\n",
      "Downloading video41.mp4 to train_video_40.mp4\n",
      "Downloading video493.mp4 to train_video_492.mp4\n",
      "Downloading video380.mp4 to train_video_379.mp4\n",
      "Downloading video188.mp4 to train_video_187.mp4\n",
      "Downloading video217.mp4 to train_video_216.mp4\n",
      "Downloading video53.mp4 to train_video_52.mp4\n",
      "Downloading video338.mp4 to train_video_337.mp4\n",
      "Downloading video20.mp4 to train_video_756.mp4\n",
      "Downloading video20.mp4 to train_video_727.mp4\n",
      "Downloading video20.mp4 to train_video_732.mp4\n",
      "Downloading video296.mp4 to train_video_295.mp4\n",
      "Downloading video20.mp4 to train_video_709.mp4\n",
      "Downloading video252.mp4 to train_video_251.mp4\n",
      "Downloading video20.mp4 to train_video_734.mp4\n",
      "Downloading video462.mp4 to train_video_461.mp4\n",
      "Downloading video456.mp4 to train_video_455.mp4\n",
      "Downloading video20.mp4 to train_video_860.mp4\n",
      "Downloading video270.mp4 to train_video_269.mp4\n",
      "Downloading video202.mp4 to train_video_201.mp4\n",
      "Downloading video162.mp4 to train_video_161.mp4\n",
      "Downloading video20.mp4 to train_video_563.mp4\n",
      "Downloading video20.mp4 to train_video_737.mp4\n",
      "Downloading video402.mp4 to train_video_401.mp4\n",
      "Downloading video20.mp4 to train_video_710.mp4\n",
      "Downloading video477.mp4 to train_video_476.mp4\n",
      "Downloading video20.mp4 to train_video_779.mp4\n",
      "Downloading video106.mp4 to train_video_105.mp4\n",
      "Downloading video20.mp4 to train_video_573.mp4\n",
      "Downloading video390.mp4 to train_video_389.mp4\n",
      "Downloading video2.mp4 to train_video_1.mp4\n",
      "Downloading video20.mp4 to train_video_808.mp4\n",
      "Downloading video20.mp4 to train_video_569.mp4\n",
      "Downloading video81.mp4 to train_video_80.mp4\n",
      "Downloading video206.mp4 to train_video_205.mp4\n",
      "Downloading video35.mp4 to train_video_34.mp4\n",
      "Downloading video20.mp4 to train_video_783.mp4\n",
      "Downloading video509.mp4 to train_video_508.mp4\n",
      "Downloading video428.mp4 to train_video_427.mp4\n",
      "Downloading video455.mp4 to train_video_454.mp4\n",
      "Downloading video367.mp4 to train_video_366.mp4\n",
      "Downloading video92.mp4 to train_video_91.mp4\n",
      "Downloading video340.mp4 to train_video_339.mp4\n",
      "Downloading video20.mp4 to train_video_572.mp4\n",
      "Downloading video346.mp4 to train_video_345.mp4\n",
      "Downloading video20.mp4 to train_video_784.mp4\n",
      "Downloading video242.mp4 to train_video_241.mp4\n",
      "Downloading video14.mp4 to train_video_13.mp4\n",
      "Downloading video316.mp4 to train_video_315.mp4\n",
      "Downloading video20.mp4 to train_video_608.mp4\n",
      "Downloading video388.mp4 to train_video_387.mp4\n",
      "Downloading video274.mp4 to train_video_273.mp4\n",
      "Downloading video167.mp4 to train_video_166.mp4\n",
      "Downloading video20.mp4 to train_video_856.mp4\n",
      "Downloading video20.mp4 to train_video_654.mp4\n",
      "Downloading video485.mp4 to train_video_484.mp4\n",
      "Downloading video20.mp4 to train_video_845.mp4\n",
      "Downloading video505.mp4 to train_video_504.mp4\n",
      "Downloading video244.mp4 to train_video_243.mp4\n",
      "Downloading video20.mp4 to train_video_574.mp4\n",
      "Downloading video20.mp4 to train_video_570.mp4\n",
      "Downloading video20.mp4 to train_video_694.mp4\n",
      "Downloading video190.mp4 to train_video_189.mp4\n",
      "Downloading video20.mp4 to train_video_790.mp4\n",
      "Downloading video20.mp4 to train_video_707.mp4\n",
      "Downloading video476.mp4 to train_video_475.mp4\n",
      "Downloading video20.mp4 to train_video_689.mp4\n",
      "Downloading video511.mp4 to train_video_510.mp4\n",
      "Downloading video59.mp4 to train_video_58.mp4\n",
      "Downloading video475.mp4 to train_video_474.mp4\n",
      "Downloading video20.mp4 to train_video_568.mp4\n",
      "Downloading video20.mp4 to train_video_755.mp4\n",
      "Downloading video253.mp4 to train_video_252.mp4\n",
      "Downloading video22.mp4 to train_video_21.mp4\n",
      "Downloading video314.mp4 to train_video_313.mp4\n",
      "Downloading video460.mp4 to train_video_459.mp4\n",
      "Downloading video161.mp4 to train_video_160.mp4\n",
      "Downloading video277.mp4 to train_video_276.mp4\n",
      "Downloading video192.mp4 to train_video_191.mp4\n",
      "Downloading video386.mp4 to train_video_385.mp4\n",
      "Downloading video20.mp4 to train_video_813.mp4\n",
      "Downloading video414.mp4 to train_video_413.mp4\n",
      "Downloading video492.mp4 to train_video_491.mp4\n",
      "Downloading video344.mp4 to train_video_343.mp4\n",
      "Downloading video20.mp4 to train_video_777.mp4\n",
      "Downloading video309.mp4 to train_video_308.mp4\n",
      "Downloading video20.mp4 to train_video_669.mp4\n",
      "Downloading video131.mp4 to train_video_130.mp4\n",
      "Downloading video20.mp4 to train_video_671.mp4\n",
      "Downloading video100.mp4 to train_video_99.mp4\n",
      "Downloading video373.mp4 to train_video_372.mp4\n",
      "Downloading video88.mp4 to train_video_87.mp4\n",
      "Downloading video459.mp4 to train_video_458.mp4\n",
      "Downloading video331.mp4 to train_video_330.mp4\n",
      "Downloading video215.mp4 to train_video_214.mp4\n",
      "Downloading video467.mp4 to train_video_466.mp4\n",
      "Downloading video122.mp4 to train_video_121.mp4\n",
      "Downloading video20.mp4 to train_video_622.mp4\n",
      "Downloading video21.mp4 to train_video_20.mp4\n",
      "Downloading video20.mp4 to train_video_708.mp4\n",
      "Downloading video72.mp4 to train_video_71.mp4\n",
      "Downloading video107.mp4 to train_video_106.mp4\n",
      "Downloading video271.mp4 to train_video_270.mp4\n",
      "Downloading video436.mp4 to train_video_435.mp4\n",
      "Downloading video103.mp4 to train_video_102.mp4\n",
      "Downloading video67.mp4 to test_video_66.mp4\n",
      "Downloading video435.mp4 to test_video_434.mp4\n",
      "Downloading video199.mp4 to test_video_198.mp4\n",
      "Downloading video213.mp4 to test_video_212.mp4\n",
      "Downloading video20.mp4 to test_video_801.mp4\n",
      "Downloading video544.mp4 to test_video_543.mp4\n",
      "Downloading video281.mp4 to test_video_280.mp4\n",
      "Downloading video297.mp4 to test_video_296.mp4\n",
      "Downloading video366.mp4 to test_video_365.mp4\n",
      "Downloading video20.mp4 to test_video_817.mp4\n",
      "Downloading video20.mp4 to test_video_718.mp4\n",
      "Downloading video20.mp4 to test_video_644.mp4\n",
      "Downloading video20.mp4 to test_video_713.mp4\n",
      "Downloading video315.mp4 to test_video_314.mp4\n",
      "Downloading video312.mp4 to test_video_311.mp4\n",
      "Downloading video523.mp4 to test_video_522.mp4\n",
      "Downloading video443.mp4 to test_video_442.mp4\n",
      "Downloading video20.mp4 to test_video_584.mp4\n",
      "Downloading video412.mp4 to test_video_411.mp4\n",
      "Downloading video20.mp4 to test_video_849.mp4\n",
      "Downloading video68.mp4 to test_video_67.mp4\n",
      "Downloading video20.mp4 to test_video_567.mp4\n",
      "Downloading video276.mp4 to test_video_275.mp4\n",
      "Downloading video20.mp4 to test_video_628.mp4\n",
      "Downloading video20.mp4 to test_video_797.mp4\n",
      "Downloading video20.mp4 to test_video_811.mp4\n",
      "Downloading video20.mp4 to test_video_778.mp4\n",
      "Downloading video20.mp4 to test_video_685.mp4\n",
      "Downloading video327.mp4 to test_video_326.mp4\n",
      "Downloading video20.mp4 to test_video_638.mp4\n",
      "Downloading video520.mp4 to test_video_519.mp4\n",
      "Downloading video469.mp4 to test_video_468.mp4\n",
      "Downloading video413.mp4 to test_video_412.mp4\n",
      "Downloading video20.mp4 to test_video_597.mp4\n",
      "Downloading video527.mp4 to test_video_526.mp4\n",
      "Downloading video548.mp4 to test_video_547.mp4\n",
      "Downloading video214.mp4 to test_video_213.mp4\n",
      "Downloading video515.mp4 to test_video_514.mp4\n",
      "Downloading video40.mp4 to test_video_39.mp4\n",
      "Downloading video20.mp4 to test_video_776.mp4\n",
      "Downloading video169.mp4 to test_video_168.mp4\n",
      "Downloading video440.mp4 to test_video_439.mp4\n",
      "Downloading video468.mp4 to test_video_467.mp4\n",
      "Downloading video31.mp4 to test_video_30.mp4\n",
      "Downloading video339.mp4 to test_video_338.mp4\n",
      "Downloading video209.mp4 to test_video_208.mp4\n",
      "Downloading video140.mp4 to test_video_139.mp4\n",
      "Downloading video20.mp4 to test_video_839.mp4\n",
      "Downloading video450.mp4 to test_video_449.mp4\n",
      "Downloading video20.mp4 to test_video_595.mp4\n",
      "Downloading video480.mp4 to test_video_479.mp4\n",
      "Downloading video20.mp4 to test_video_606.mp4\n",
      "Downloading video261.mp4 to test_video_260.mp4\n",
      "Downloading video20.mp4 to test_video_829.mp4\n",
      "Downloading video425.mp4 to test_video_424.mp4\n",
      "Downloading video20.mp4 to test_video_677.mp4\n",
      "Downloading video24.mp4 to test_video_23.mp4\n",
      "Downloading video211.mp4 to test_video_210.mp4\n",
      "Downloading video197.mp4 to test_video_196.mp4\n",
      "Downloading video20.mp4 to test_video_742.mp4\n",
      "Downloading video111.mp4 to test_video_110.mp4\n",
      "Downloading video384.mp4 to test_video_383.mp4\n",
      "Downloading video228.mp4 to test_video_227.mp4\n",
      "Downloading video514.mp4 to test_video_513.mp4\n",
      "Downloading video20.mp4 to test_video_663.mp4\n",
      "Downloading video87.mp4 to test_video_86.mp4\n",
      "Downloading video97.mp4 to test_video_96.mp4\n",
      "Downloading video20.mp4 to test_video_762.mp4\n",
      "Downloading video542.mp4 to test_video_541.mp4\n",
      "Downloading video293.mp4 to test_video_292.mp4\n",
      "Downloading video137.mp4 to test_video_136.mp4\n",
      "Downloading video110.mp4 to test_video_109.mp4\n",
      "Downloading video210.mp4 to test_video_209.mp4\n",
      "Downloading video20.mp4 to test_video_670.mp4\n",
      "Downloading video20.mp4 to test_video_701.mp4\n",
      "Downloading video64.mp4 to test_video_63.mp4\n",
      "Downloading video20.mp4 to test_video_566.mp4\n",
      "Downloading video20.mp4 to test_video_859.mp4\n",
      "Downloading video329.mp4 to test_video_328.mp4\n",
      "Downloading video66.mp4 to test_video_65.mp4\n",
      "Downloading video20.mp4 to test_video_575.mp4\n",
      "Downloading video79.mp4 to test_video_78.mp4\n",
      "Downloading video301.mp4 to test_video_300.mp4\n",
      "Downloading video20.mp4 to test_video_667.mp4\n",
      "Downloading video20.mp4 to test_video_586.mp4\n",
      "Downloading video347.mp4 to test_video_346.mp4\n",
      "Downloading video20.mp4 to test_video_637.mp4\n",
      "Downloading video452.mp4 to test_video_451.mp4\n",
      "Downloading video549.mp4 to test_video_548.mp4\n",
      "Downloading video20.mp4 to test_video_699.mp4\n",
      "Downloading video50.mp4 to test_video_49.mp4\n",
      "Downloading video121.mp4 to test_video_120.mp4\n",
      "Downloading video20.mp4 to test_video_828.mp4\n",
      "Downloading video300.mp4 to test_video_299.mp4\n",
      "Downloading video138.mp4 to test_video_137.mp4\n",
      "Downloading video266.mp4 to test_video_265.mp4\n",
      "Downloading video20.mp4 to test_video_858.mp4\n",
      "Downloading video441.mp4 to test_video_440.mp4\n",
      "Downloading video20.mp4 to test_video_787.mp4\n",
      "Downloading video34.mp4 to test_video_33.mp4\n",
      "Downloading video32.mp4 to test_video_31.mp4\n",
      "Downloading video20.mp4 to test_video_706.mp4\n",
      "Downloading video20.mp4 to test_video_722.mp4\n",
      "Downloading video368.mp4 to test_video_367.mp4\n",
      "Downloading video77.mp4 to test_video_76.mp4\n",
      "Downloading video248.mp4 to test_video_247.mp4\n",
      "Downloading video478.mp4 to test_video_477.mp4\n",
      "Downloading video236.mp4 to test_video_235.mp4\n",
      "Downloading video73.mp4 to test_video_72.mp4\n",
      "Downloading video78.mp4 to test_video_77.mp4\n",
      "Downloading video20.mp4 to test_video_749.mp4\n",
      "Downloading video543.mp4 to test_video_542.mp4\n",
      "Downloading video410.mp4 to test_video_409.mp4\n",
      "Downloading video287.mp4 to test_video_286.mp4\n",
      "Downloading video175.mp4 to test_video_174.mp4\n",
      "Downloading video20.mp4 to test_video_690.mp4\n",
      "Downloading video20.mp4 to test_video_861.mp4\n",
      "Downloading video295.mp4 to test_video_294.mp4\n",
      "Downloading video382.mp4 to test_video_381.mp4\n",
      "Downloading video482.mp4 to test_video_481.mp4\n",
      "Downloading video20.mp4 to test_video_676.mp4\n",
      "Downloading video20.mp4 to test_video_752.mp4\n",
      "Downloading video20.mp4 to test_video_679.mp4\n",
      "Downloading video345.mp4 to test_video_344.mp4\n",
      "Downloading video291.mp4 to test_video_290.mp4\n",
      "Downloading video20.mp4 to test_video_812.mp4\n",
      "Downloading video216.mp4 to test_video_215.mp4\n",
      "Downloading video6.mp4 to test_video_5.mp4\n",
      "Downloading video55.mp4 to test_video_54.mp4\n",
      "Downloading video423.mp4 to test_video_422.mp4\n",
      "Downloading video376.mp4 to test_video_375.mp4\n",
      "Downloading video245.mp4 to test_video_244.mp4\n",
      "Downloading video98.mp4 to test_video_97.mp4\n",
      "Downloading video20.mp4 to test_video_717.mp4\n",
      "Downloading video20.mp4 to test_video_826.mp4\n",
      "Downloading video465.mp4 to test_video_464.mp4\n",
      "Downloading video20.mp4 to test_video_827.mp4\n",
      "Downloading video20.mp4 to test_video_815.mp4\n",
      "Downloading video85.mp4 to test_video_84.mp4\n",
      "Downloading video11.mp4 to test_video_10.mp4\n",
      "Downloading video20.mp4 to test_video_674.mp4\n",
      "Downloading video356.mp4 to test_video_355.mp4\n",
      "Downloading video383.mp4 to test_video_382.mp4\n",
      "Downloading video119.mp4 to test_video_118.mp4\n",
      "Downloading video363.mp4 to test_video_362.mp4\n",
      "Downloading video251.mp4 to test_video_250.mp4\n",
      "Downloading video30.mp4 to test_video_29.mp4\n",
      "Downloading video20.mp4 to test_video_719.mp4\n",
      "Downloading video20.mp4 to test_video_761.mp4\n",
      "Downloading video303.mp4 to test_video_302.mp4\n",
      "Downloading video334.mp4 to test_video_333.mp4\n",
      "Downloading video82.mp4 to test_video_81.mp4\n",
      "Downloading video20.mp4 to test_video_639.mp4\n",
      "Downloading video389.mp4 to test_video_388.mp4\n",
      "Downloading video538.mp4 to test_video_537.mp4\n",
      "Downloading video20.mp4 to test_video_560.mp4\n",
      "Downloading video20.mp4 to test_video_758.mp4\n",
      "Downloading video364.mp4 to test_video_363.mp4\n",
      "Downloading video517.mp4 to test_video_516.mp4\n",
      "Downloading video20.mp4 to test_video_739.mp4\n",
      "Downloading video448.mp4 to test_video_447.mp4\n",
      "Downloading video20.mp4 to test_video_819.mp4\n",
      "Downloading video458.mp4 to test_video_457.mp4\n",
      "Downloading video267.mp4 to test_video_266.mp4\n",
      "Downloading video232.mp4 to test_video_231.mp4\n",
      "Downloading video324.mp4 to test_video_323.mp4\n",
      "Downloading video212.mp4 to test_video_211.mp4\n",
      "Downloading video260.mp4 to test_video_259.mp4\n",
      "Downloading video8.mp4 to test_video_7.mp4\n",
      "Downloading video282.mp4 to test_video_281.mp4\n",
      "Downloading video156.mp4 to test_video_155.mp4\n",
      "Training DataFrame:\n",
      "              video_path  label\n",
      "0    train_video_796.mp4      2\n",
      "1    train_video_101.mp4      1\n",
      "2    train_video_798.mp4      2\n",
      "3    train_video_530.mp4      2\n",
      "4    train_video_430.mp4      0\n",
      "..                   ...    ...\n",
      "679   train_video_71.mp4      1\n",
      "680  train_video_106.mp4      1\n",
      "681  train_video_270.mp4      1\n",
      "682  train_video_435.mp4      0\n",
      "683  train_video_102.mp4      1\n",
      "\n",
      "[684 rows x 2 columns]\n",
      "\n",
      "Test DataFrame:\n",
      "             video_path  label\n",
      "0     test_video_66.mp4      1\n",
      "1    test_video_434.mp4      0\n",
      "2    test_video_198.mp4      1\n",
      "3    test_video_212.mp4      1\n",
      "4    test_video_801.mp4      2\n",
      "..                  ...    ...\n",
      "166  test_video_211.mp4      1\n",
      "167  test_video_259.mp4      1\n",
      "168    test_video_7.mp4      1\n",
      "169  test_video_281.mp4      1\n",
      "170  test_video_155.mp4      1\n",
      "\n",
      "[171 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the bucket name and a placeholder function for downloading\n",
    "bucket_name = 'sagemaker-us-east-2-058264083825'\n",
    "\n",
    "def download_video_from_s3(bucket_name, object_key, download_path):\n",
    "    # Placeholder function: Replace with your actual download logic\n",
    "    print(f\"Downloading {object_key} to {download_path}\")\n",
    "    # Your download code here\n",
    "\n",
    "# Download training videos and match with labels\n",
    "train_download_paths = []\n",
    "train_labels = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    video_name = row['Video Name']\n",
    "    label = row['Label']\n",
    "    download_path = f'train_video_{idx}.mp4'\n",
    "    download_video_from_s3(bucket_name, video_name, download_path)\n",
    "    train_download_paths.append(download_path)\n",
    "    train_labels.append(label)\n",
    "\n",
    "# Download test videos and match with labels\n",
    "test_download_paths = []\n",
    "test_labels = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    video_name = row['Video Name']\n",
    "    label = row['Label']\n",
    "    download_path = f'test_video_{idx}.mp4'\n",
    "    download_video_from_s3(bucket_name, video_name, download_path)\n",
    "    test_download_paths.append(download_path)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# Create new DataFrames for the downloaded paths and labels\n",
    "train_df_downloaded = pd.DataFrame({\n",
    "    'video_path': train_download_paths,\n",
    "    'label': train_labels\n",
    "})\n",
    "\n",
    "test_df_downloaded = pd.DataFrame({\n",
    "    'video_path': test_download_paths,\n",
    "    'label': test_labels\n",
    "})\n",
    "\n",
    "# Output the DataFrames\n",
    "print(\"Training DataFrame:\")\n",
    "print(train_df_downloaded)\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df_downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb72e5-cc66-419b-9b11-6803010a660c",
   "metadata": {},
   "source": [
    "# Extract Features from BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b536e159-9f9c-4863-bd1c-7158d9b50c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease \n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease    \n",
      "Fetched 257 kB in 1s (324 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# This command installs the necessary OpenGL library for OpenCV\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123d2d2c-ea11-4936-b88f-5df4d1fcc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ae34e1-d0dd-493f-908b-2f522b3a3ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Extracting Features: 100%|| 54/54 [01:58<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define Dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoded_text = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        encoded_text = {key: value.squeeze(0) for key, value in encoded_text.items()}\n",
    "        return encoded_text\n",
    "\n",
    "# Function to extract features in batches\n",
    "def extract_features(texts, batch_size=16):\n",
    "    dataset = SentimentDataset(texts, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    model.eval()\n",
    "    features = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "            inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model(**inputs)\n",
    "            features.append(outputs.logits.detach().cpu().numpy())\n",
    "\n",
    "            # Clear unnecessary data\n",
    "            del inputs, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features\n",
    "\n",
    "# Assuming df is your DataFrame with 'Text' column\n",
    "texts = df['Text'].astype(str).tolist()  # Ensure texts are strings\n",
    "text_features = extract_features(texts)\n",
    "\n",
    "# Add extracted features to the DataFrame and ensure correct shape\n",
    "df['Text_Features'] = list(text_features)\n",
    "\n",
    "# Ensure all text features have the correct shape\n",
    "df['Text_Features'] = df['Text_Features'].apply(lambda x: x.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65560419-bd79-48ad-bc8f-651c786d620a",
   "metadata": {},
   "source": [
    "# Hybrid Model: Run #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "637d9af0-dc07-4920-a486-15d344e1c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 3, 112, 112, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " resize_video_2 (ResizeVide  (None, 3, 112, 112, 3)       0         ['input_5[0][0]']             \n",
      " o)                                                                                               \n",
      "                                                                                                  \n",
      " project_4 (Project)         (None, 3, 112, 112, 32)      128       ['resize_video_2[0][0]']      \n",
      "                                                                                                  \n",
      " residual_main_4 (ResidualM  (None, 3, 112, 112, 32)      16480     ['resize_video_2[0][0]']      \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 3, 112, 112, 32)      0         ['project_4[0][0]',           \n",
      "                                                                     'residual_main_4[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_4 (MaxPoolin  (None, 3, 56, 56, 32)        0         ['add_4[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " project_5 (Project)         (None, 3, 56, 56, 64)        2112      ['max_pooling3d_4[0][0]']     \n",
      "                                                                                                  \n",
      " residual_main_5 (ResidualM  (None, 3, 56, 56, 64)        80384     ['max_pooling3d_4[0][0]']     \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 3, 56, 56, 64)        0         ['project_5[0][0]',           \n",
      "                                                                     'residual_main_5[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_5 (MaxPoolin  (None, 3, 28, 28, 64)        0         ['add_5[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling3d_2  (None, 64)                   0         ['max_pooling3d_5[0][0]']     \n",
      "  (GlobalAveragePooling3D)                                                                        \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 67)                   0         ['global_average_pooling3d_2[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 3)                    204       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 99308 (387.92 KB)\n",
      "Trainable params: 99308 (387.92 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "684/684 [==============================] - 501s 727ms/step - loss: 1.0982 - accuracy: 0.4488 - val_loss: 1.0849 - val_accuracy: 0.4561\n",
      "Epoch 2/10\n",
      "684/684 [==============================] - 492s 720ms/step - loss: 1.0129 - accuracy: 0.4561 - val_loss: 1.0455 - val_accuracy: 0.4561\n",
      "Epoch 3/10\n",
      "684/684 [==============================] - 486s 711ms/step - loss: 0.9980 - accuracy: 0.4737 - val_loss: 1.0053 - val_accuracy: 0.4561\n",
      "Epoch 4/10\n",
      "684/684 [==============================] - 513s 750ms/step - loss: 0.9822 - accuracy: 0.4971 - val_loss: 0.9779 - val_accuracy: 0.4561\n",
      "Epoch 5/10\n",
      "684/684 [==============================] - 483s 706ms/step - loss: 0.9706 - accuracy: 0.5292 - val_loss: 0.9660 - val_accuracy: 0.4561\n",
      "Epoch 6/10\n",
      "684/684 [==============================] - 494s 722ms/step - loss: 0.9619 - accuracy: 0.5526 - val_loss: 0.9570 - val_accuracy: 0.4561\n",
      "Epoch 7/10\n",
      "684/684 [==============================] - 504s 737ms/step - loss: 0.9528 - accuracy: 0.5906 - val_loss: 0.9488 - val_accuracy: 0.4561\n",
      "Epoch 8/10\n",
      "684/684 [==============================] - 488s 713ms/step - loss: 0.9438 - accuracy: 0.6155 - val_loss: 0.9408 - val_accuracy: 0.7895\n",
      "Epoch 9/10\n",
      "684/684 [==============================] - 499s 730ms/step - loss: 0.9348 - accuracy: 0.6433 - val_loss: 0.9343 - val_accuracy: 0.7836\n",
      "Epoch 10/10\n",
      "684/684 [==============================] - 503s 736ms/step - loss: 0.9273 - accuracy: 0.6564 - val_loss: 0.9283 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import einops\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define dimensions\n",
    "HEIGHT = 112\n",
    "WIDTH = 112\n",
    "N_FRAMES = 3\n",
    "BATCH_SIZE = 1\n",
    "MAX_TEXT_FEATURES = 3  # This should match the number of classes from the LLM\n",
    "\n",
    "# Define Conv2Plus1D layer\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, kernel_size[1], kernel_size[2]), padding=padding),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(kernel_size[0], 1, 1), padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Define Project layer\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv3D(filters, kernel_size=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Define ResidualMain layer\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Add residual block\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    out = ResidualMain(filters, kernel_size)(input)\n",
    "    res = input\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "    return layers.add([res, out])\n",
    "\n",
    "# Resize video frames\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Video input model\n",
    "def build_video_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = ResizeVideo(HEIGHT, WIDTH)(inputs)\n",
    "    x = add_residual_block(x, filters=32, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=64, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Combined model\n",
    "def build_combined_model(video_input_shape, text_feature_shape):\n",
    "    video_inputs, video_features = build_video_model(video_input_shape)\n",
    "    text_inputs = tf.keras.Input(shape=text_feature_shape)\n",
    "\n",
    "    combined_features = tf.keras.layers.concatenate([video_features, text_inputs])\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(combined_features)  # Assuming 3 classes for classification\n",
    "    model = tf.keras.Model(inputs=[video_inputs, text_inputs], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "video_input_shape = (N_FRAMES, HEIGHT, WIDTH, 3)\n",
    "text_feature_shape = (MAX_TEXT_FEATURES,)\n",
    "\n",
    "model = build_combined_model(video_input_shape, text_feature_shape)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# FrameGenerator class to preprocess video frames\n",
    "class FrameGenerator:\n",
    "    def __init__(self, paths, labels, features, n_frames, frame_size=(HEIGHT, WIDTH), training=False):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.n_frames = n_frames\n",
    "        self.frame_size = frame_size\n",
    "        self.training = training\n",
    "\n",
    "    def __call__(self):\n",
    "        for video_path, label, feature in zip(self.paths, self.labels, self.features):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "            while len(frames) < self.n_frames:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, self.frame_size)  # Resize frames to smaller size\n",
    "                frame = frame / 255.0  # Normalize\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "            if len(frames) < self.n_frames:\n",
    "                frames.extend([np.zeros(self.frame_size + (3,))] * (self.n_frames - len(frames)))  # Pad with zeros\n",
    "            frames = np.array(frames)\n",
    "\n",
    "            yield (frames, feature), label\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=(N_FRAMES, HEIGHT, WIDTH, 3), dtype=tf.float32), tf.TensorSpec(shape=(MAX_TEXT_FEATURES,), dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    ")\n",
    "\n",
    "def create_dataset(paths, labels, features, n_frames, batch_size, frame_size, training=False):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        FrameGenerator(paths, labels, features, n_frames, frame_size, training=training),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_paths = train_df['Video Name'].tolist()\n",
    "train_labels = train_df['Label'].tolist()\n",
    "train_features = np.array(train_df['Text_Features'].tolist())\n",
    "\n",
    "val_paths = test_df['Video Name'].tolist()\n",
    "val_labels = test_df['Label'].tolist()\n",
    "val_features = np.array(test_df['Text_Features'].tolist())\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, train_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH), training=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, val_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH))\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d198f6-ea1b-4186-8d6c-1a5e1559cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 112, 112, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " resize_video (ResizeVideo)  (None, 3, 112, 112, 3)       0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " project (Project)           (None, 3, 112, 112, 32)      128       ['resize_video[0][0]']        \n",
      "                                                                                                  \n",
      " residual_main (ResidualMai  (None, 3, 112, 112, 32)      16480     ['resize_video[0][0]']        \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 3, 112, 112, 32)      0         ['project[0][0]',             \n",
      "                                                                     'residual_main[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3  (None, 3, 56, 56, 32)        0         ['add[0][0]']                 \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " project_1 (Project)         (None, 3, 56, 56, 64)        2112      ['max_pooling3d[0][0]']       \n",
      "                                                                                                  \n",
      " residual_main_1 (ResidualM  (None, 3, 56, 56, 64)        80384     ['max_pooling3d[0][0]']       \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 3, 56, 56, 64)        0         ['project_1[0][0]',           \n",
      "                                                                     'residual_main_1[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPoolin  (None, 3, 28, 28, 64)        0         ['add_1[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling3d (  (None, 64)                   0         ['max_pooling3d_1[0][0]']     \n",
      " GlobalAveragePooling3D)                                                                          \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 67)                   0         ['global_average_pooling3d[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 3)                    204       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 99308 (387.92 KB)\n",
      "Trainable params: 99308 (387.92 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "685/685 [==============================] - 516s 744ms/step - loss: 1.1116 - accuracy: 0.4380 - val_loss: 0.9735 - val_accuracy: 0.4535\n",
      "Epoch 2/10\n",
      "685/685 [==============================] - 492s 718ms/step - loss: 1.0375 - accuracy: 0.4482 - val_loss: 0.9684 - val_accuracy: 0.4535\n",
      "Epoch 3/10\n",
      "685/685 [==============================] - 502s 734ms/step - loss: 1.0219 - accuracy: 0.4453 - val_loss: 0.9665 - val_accuracy: 0.4535\n",
      "Epoch 4/10\n",
      "685/685 [==============================] - 501s 731ms/step - loss: 1.0154 - accuracy: 0.4511 - val_loss: 0.9650 - val_accuracy: 0.4535\n",
      "Epoch 5/10\n",
      "685/685 [==============================] - 499s 729ms/step - loss: 1.0110 - accuracy: 0.4584 - val_loss: 0.9636 - val_accuracy: 0.4535\n",
      "Epoch 6/10\n",
      "685/685 [==============================] - 485s 708ms/step - loss: 1.0069 - accuracy: 0.4540 - val_loss: 0.9618 - val_accuracy: 0.4535\n",
      "Epoch 7/10\n",
      "685/685 [==============================] - 488s 713ms/step - loss: 1.0038 - accuracy: 0.4672 - val_loss: 0.9602 - val_accuracy: 0.5698\n",
      "Epoch 8/10\n",
      "685/685 [==============================] - 501s 731ms/step - loss: 1.0006 - accuracy: 0.4686 - val_loss: 0.9593 - val_accuracy: 0.6337\n",
      "Epoch 9/10\n",
      "685/685 [==============================] - 514s 750ms/step - loss: 0.9979 - accuracy: 0.4788 - val_loss: 0.9582 - val_accuracy: 0.6686\n",
      "Epoch 10/10\n",
      "685/685 [==============================] - 511s 745ms/step - loss: 0.9952 - accuracy: 0.4832 - val_loss: 0.9590 - val_accuracy: 0.7267\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import einops\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define dimensions\n",
    "HEIGHT = 112\n",
    "WIDTH = 112\n",
    "N_FRAMES = 3\n",
    "BATCH_SIZE = 1\n",
    "MAX_TEXT_FEATURES = 3  # This should match the number of classes from the LLM\n",
    "\n",
    "# Define Conv2Plus1D layer\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, kernel_size[1], kernel_size[2]), padding=padding),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(kernel_size[0], 1, 1), padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Define Project layer\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv3D(filters, kernel_size=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Define ResidualMain layer\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Add residual block\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    out = ResidualMain(filters, kernel_size)(input)\n",
    "    res = input\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "    return layers.add([res, out])\n",
    "\n",
    "# Resize video frames\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Video input model\n",
    "def build_video_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = ResizeVideo(HEIGHT, WIDTH)(inputs)\n",
    "    x = add_residual_block(x, filters=32, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=64, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Combined model\n",
    "def build_combined_model(video_input_shape, text_feature_shape):\n",
    "    video_inputs, video_features = build_video_model(video_input_shape)\n",
    "    text_inputs = tf.keras.Input(shape=text_feature_shape)\n",
    "\n",
    "    combined_features = tf.keras.layers.concatenate([video_features, text_inputs])\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(combined_features)  # Assuming 3 classes for classification\n",
    "    model = tf.keras.Model(inputs=[video_inputs, text_inputs], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "video_input_shape = (N_FRAMES, HEIGHT, WIDTH, 3)\n",
    "text_feature_shape = (MAX_TEXT_FEATURES,)\n",
    "\n",
    "model = build_combined_model(video_input_shape, text_feature_shape)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# FrameGenerator class to preprocess video frames\n",
    "class FrameGenerator:\n",
    "    def __init__(self, paths, labels, features, n_frames, frame_size=(HEIGHT, WIDTH), training=False):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.n_frames = n_frames\n",
    "        self.frame_size = frame_size\n",
    "        self.training = training\n",
    "\n",
    "    def __call__(self):\n",
    "        for video_path, label, feature in zip(self.paths, self.labels, self.features):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "            while len(frames) < self.n_frames:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, self.frame_size)  # Resize frames to smaller size\n",
    "                frame = frame / 255.0  # Normalize\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "            if len(frames) < self.n_frames:\n",
    "                frames.extend([np.zeros(self.frame_size + (3,))] * (self.n_frames - len(frames)))  # Pad with zeros\n",
    "            frames = np.array(frames)\n",
    "\n",
    "            yield (frames, feature), label\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=(N_FRAMES, HEIGHT, WIDTH, 3), dtype=tf.float32), tf.TensorSpec(shape=(MAX_TEXT_FEATURES,), dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    ")\n",
    "\n",
    "def create_dataset(paths, labels, features, n_frames, batch_size, frame_size, training=False):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        FrameGenerator(paths, labels, features, n_frames, frame_size, training=training),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_paths = train_df['Video Name'].tolist()\n",
    "train_labels = train_df['Label'].tolist()\n",
    "train_features = np.array(train_df['Text_Features'].tolist())\n",
    "\n",
    "val_paths = test_df['Video Name'].tolist()\n",
    "val_labels = test_df['Label'].tolist()\n",
    "val_features = np.array(test_df['Text_Features'].tolist())\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, train_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH), training=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, val_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH))\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45487aa-9866-4c3b-a00e-c9eb67648c6e",
   "metadata": {},
   "source": [
    "# Hybrid Model: Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "052f35a9-49b3-43bf-93f0-4c0b47d9e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 112, 112, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " resize_video (ResizeVideo)  (None, 3, 112, 112, 3)       0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " video_data_augmentation (V  (None, 3, 112, 112, 3)       0         ['resize_video[0][0]']        \n",
      " ideoDataAugmentation)                                                                            \n",
      "                                                                                                  \n",
      " project (Project)           (None, 3, 112, 112, 32)      128       ['video_data_augmentation[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " residual_main (ResidualMai  (None, 3, 112, 112, 32)      16480     ['video_data_augmentation[0][0\n",
      " n)                                                                 ]']                           \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 3, 112, 112, 32)      0         ['project[0][0]',             \n",
      "                                                                     'residual_main[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3  (None, 3, 56, 56, 32)        0         ['add[0][0]']                 \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " project_1 (Project)         (None, 3, 56, 56, 64)        2112      ['max_pooling3d[0][0]']       \n",
      "                                                                                                  \n",
      " residual_main_1 (ResidualM  (None, 3, 56, 56, 64)        80384     ['max_pooling3d[0][0]']       \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 3, 56, 56, 64)        0         ['project_1[0][0]',           \n",
      "                                                                     'residual_main_1[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPoolin  (None, 3, 28, 28, 64)        0         ['add_1[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " project_2 (Project)         (None, 3, 28, 28, 128)       8320      ['max_pooling3d_1[0][0]']     \n",
      "                                                                                                  \n",
      " residual_main_2 (ResidualM  (None, 3, 28, 28, 128)       320512    ['max_pooling3d_1[0][0]']     \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 3, 28, 28, 128)       0         ['project_2[0][0]',           \n",
      "                                                                     'residual_main_2[0][0]']     \n",
      "                                                                                                  \n",
      " global_average_pooling3d (  (None, 128)                  0         ['add_2[0][0]']               \n",
      " GlobalAveragePooling3D)                                                                          \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 131)                  0         ['global_average_pooling3d[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 3)                    396       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 428332 (1.63 MB)\n",
      "Trainable params: 428332 (1.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "684/684 [==============================] - 621s 900ms/step - loss: 1.2552 - accuracy: 0.4444 - val_loss: 1.3202 - val_accuracy: 0.4561\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 623s 910ms/step - loss: 1.0350 - accuracy: 0.4518 - val_loss: 1.0846 - val_accuracy: 0.4561\n",
      "Epoch 3/20\n",
      "684/684 [==============================] - 644s 942ms/step - loss: 1.0062 - accuracy: 0.4751 - val_loss: 1.0365 - val_accuracy: 0.4561\n",
      "Epoch 4/20\n",
      "684/684 [==============================] - 624s 912ms/step - loss: 0.9899 - accuracy: 0.4971 - val_loss: 0.9903 - val_accuracy: 0.4561\n",
      "Epoch 5/20\n",
      "684/684 [==============================] - 648s 947ms/step - loss: 0.9779 - accuracy: 0.5307 - val_loss: 0.9954 - val_accuracy: 0.4561\n",
      "Epoch 6/20\n",
      "684/684 [==============================] - 640s 936ms/step - loss: 0.9694 - accuracy: 0.5482 - val_loss: 0.9655 - val_accuracy: 0.4561\n",
      "Epoch 7/20\n",
      "684/684 [==============================] - 651s 952ms/step - loss: 0.9576 - accuracy: 0.5804 - val_loss: 0.9572 - val_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "684/684 [==============================] - 642s 938ms/step - loss: 0.9495 - accuracy: 0.6067 - val_loss: 0.9515 - val_accuracy: 0.7310\n",
      "Epoch 9/20\n",
      "684/684 [==============================] - 627s 917ms/step - loss: 0.9407 - accuracy: 0.6345 - val_loss: 0.9465 - val_accuracy: 0.7427\n",
      "Epoch 10/20\n",
      "684/684 [==============================] - 627s 916ms/step - loss: 0.9347 - accuracy: 0.6433 - val_loss: 0.9422 - val_accuracy: 0.7602\n",
      "Epoch 11/20\n",
      "684/684 [==============================] - 621s 908ms/step - loss: 0.9302 - accuracy: 0.6316 - val_loss: 0.9372 - val_accuracy: 0.7193\n",
      "Epoch 12/20\n",
      "684/684 [==============================] - 566s 827ms/step - loss: 0.9219 - accuracy: 0.6462 - val_loss: 0.9335 - val_accuracy: 0.6784\n",
      "Epoch 13/20\n",
      "684/684 [==============================] - 553s 809ms/step - loss: 0.9173 - accuracy: 0.6594 - val_loss: 0.9362 - val_accuracy: 0.4561\n",
      "Epoch 14/20\n",
      "684/684 [==============================] - 576s 843ms/step - loss: 0.9136 - accuracy: 0.6506 - val_loss: 0.9243 - val_accuracy: 0.7368\n",
      "Epoch 15/20\n",
      "684/684 [==============================] - 564s 825ms/step - loss: 0.9080 - accuracy: 0.6711 - val_loss: 0.9227 - val_accuracy: 0.6608\n",
      "Epoch 16/20\n",
      "684/684 [==============================] - 573s 838ms/step - loss: 0.9024 - accuracy: 0.6725 - val_loss: 0.9175 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "684/684 [==============================] - 553s 808ms/step - loss: 0.8965 - accuracy: 0.6798 - val_loss: 0.9126 - val_accuracy: 0.7193\n",
      "Epoch 18/20\n",
      "684/684 [==============================] - 543s 794ms/step - loss: 0.8941 - accuracy: 0.6798 - val_loss: 0.9104 - val_accuracy: 0.7427\n",
      "Epoch 19/20\n",
      "684/684 [==============================] - 551s 805ms/step - loss: 0.8905 - accuracy: 0.6784 - val_loss: 0.9061 - val_accuracy: 0.7427\n",
      "Epoch 20/20\n",
      "684/684 [==============================] - 579s 846ms/step - loss: 0.8857 - accuracy: 0.6842 - val_loss: 0.9025 - val_accuracy: 0.7310\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import einops\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dimensions\n",
    "HEIGHT = 112\n",
    "WIDTH = 112\n",
    "N_FRAMES = 3\n",
    "BATCH_SIZE = 1\n",
    "MAX_TEXT_FEATURES = 3  # This should match the number of classes from the LLM\n",
    "\n",
    "# Define Conv2Plus1D layer\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, kernel_size[1], kernel_size[2]), padding=padding),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(kernel_size[0], 1, 1), padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Define Project layer\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv3D(filters, kernel_size=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Define ResidualMain layer\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dropout_rate=0.3, l2_strength=0.01):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Add residual block\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    out = ResidualMain(filters, kernel_size)(input)x\n",
    "    res = input\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "    return layers.add([res, out])\n",
    "\n",
    "# Resize video frames\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Data augmentation for video frames\n",
    "class VideoDataAugmentation(layers.Layer):\n",
    "    def __init__(self, frame_size):\n",
    "        super().__init__()\n",
    "        self.frame_size = frame_size\n",
    "        self.augmentation_layer = Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.1),\n",
    "            layers.RandomCrop(self.frame_size[0], self.frame_size[1])\n",
    "        ])\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.augmentation_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Video input model\n",
    "def build_video_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = ResizeVideo(HEIGHT, WIDTH)(inputs)\n",
    "    x = VideoDataAugmentation((HEIGHT, WIDTH))(x)  # Apply augmentation\n",
    "    x = add_residual_block(x, filters=32, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=64, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=128, kernel_size=(3, 3, 3))  # New block\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Combined model\n",
    "def build_combined_model(video_input_shape, text_feature_shape):\n",
    "    video_inputs, video_features = build_video_model(video_input_shape)\n",
    "    text_inputs = tf.keras.Input(shape=text_feature_shape)\n",
    "\n",
    "    combined_features = tf.keras.layers.concatenate([video_features, text_inputs])\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(combined_features)  # Assuming 3 classes for classification\n",
    "    model = tf.keras.Model(inputs=[video_inputs, text_inputs], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "video_input_shape = (N_FRAMES, HEIGHT, WIDTH, 3)\n",
    "text_feature_shape = (MAX_TEXT_FEATURES,)\n",
    "\n",
    "model = build_combined_model(video_input_shape, text_feature_shape)\n",
    "model.summary()\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "\n",
    "# Compile the model with the learning rate schedule\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# FrameGenerator class to preprocess video frames\n",
    "class FrameGenerator:\n",
    "    def __init__(self, paths, labels, features, n_frames, frame_size=(HEIGHT, WIDTH), training=False):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.n_frames = n_frames\n",
    "        self.frame_size = frame_size\n",
    "        self.training = training\n",
    "\n",
    "    def __call__(self):\n",
    "        for video_path, label, feature in zip(self.paths, self.labels, self.features):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "            while len(frames) < self.n_frames:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, self.frame_size)  # Resize frames to smaller size\n",
    "                frame = frame / 255.0  # Normalize\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "            if len(frames) < self.n_frames:\n",
    "                frames.extend([np.zeros(self.frame_size + (3,))] * (self.n_frames - len(frames)))  # Pad with zeros\n",
    "            frames = np.array(frames)\n",
    "\n",
    "            yield (frames, feature), label\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=(N_FRAMES, HEIGHT, WIDTH, 3), dtype=tf.float32), tf.TensorSpec(shape=(MAX_TEXT_FEATURES,), dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    ")\n",
    "\n",
    "def create_dataset(paths, labels, features, n_frames, batch_size, frame_size, training=False):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        FrameGenerator(paths, labels, features, n_frames, frame_size, training=training),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Assuming df is your DataFrame containing video paths, labels, and text features\n",
    "# Ensure you have a DataFrame ready with these columns: 'Video Name', 'Label', 'Text_Features'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_paths = train_df['Video Name'].tolist()\n",
    "train_labels = train_df['Label'].tolist()\n",
    "train_features = np.array(train_df['Text_Features'].tolist())\n",
    "\n",
    "val_paths = test_df['Video Name'].tolist()\n",
    "val_labels = test_df['Label'].tolist()\n",
    "val_features = np.array(test_df['Text_Features'].tolist())\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, train_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH), training=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, val_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH))\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Callbacks for early stopping and checkpointing\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(train_ds, epochs=20, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dad704ea-ba94-4f24-ae5b-5cad7deb86d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 3, 112, 112, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " resize_video_2 (ResizeVide  (None, 3, 112, 112, 3)       0         ['input_5[0][0]']             \n",
      " o)                                                                                               \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)  (None, 3, 56, 56, 32)        2624      ['resize_video_2[0][0]']      \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)  (None, 3, 28, 28, 64)        55360     ['sequential_16[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling3d_2  (None, 64)                   0         ['sequential_17[0][0]']       \n",
      "  (GlobalAveragePooling3D)                                                                        \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 67)                   0         ['global_average_pooling3d_2[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 3)                    204       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58188 (227.30 KB)\n",
      "Trainable params: 58188 (227.30 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 22:25:33.950649: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65028096 exceeds 10% of free system memory.\n",
      "2024-08-03 22:25:33.950916: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65028096 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 1s 1s/step - loss: 1.1119 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 22:25:34.698226: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65028096 exceeds 10% of free system memory.\n",
      "2024-08-03 22:25:34.698457: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65028096 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 2s 730ms/step - loss: 1.1179 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 22:25:35.432408: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65028096 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 290s 847ms/step - loss: 1.0720 - accuracy: 0.4386 - val_loss: 1.0466 - val_accuracy: 0.4035\n",
      "Epoch 2/20\n",
      "342/342 [==============================] - 289s 847ms/step - loss: 1.0221 - accuracy: 0.5322 - val_loss: 1.0162 - val_accuracy: 0.4094\n",
      "Epoch 3/20\n",
      "342/342 [==============================] - 289s 844ms/step - loss: 0.9957 - accuracy: 0.5175 - val_loss: 1.0001 - val_accuracy: 0.4211\n",
      "Epoch 4/20\n",
      "342/342 [==============================] - 283s 825ms/step - loss: 0.9804 - accuracy: 0.5307 - val_loss: 0.9905 - val_accuracy: 0.4620\n",
      "Epoch 5/20\n",
      "342/342 [==============================] - 295s 864ms/step - loss: 0.9704 - accuracy: 0.5526 - val_loss: 0.9841 - val_accuracy: 0.4678\n",
      "Epoch 6/20\n",
      "342/342 [==============================] - 286s 837ms/step - loss: 0.9631 - accuracy: 0.5775 - val_loss: 0.9792 - val_accuracy: 0.5088\n",
      "Epoch 7/20\n",
      "342/342 [==============================] - 292s 854ms/step - loss: 0.9572 - accuracy: 0.6023 - val_loss: 0.9750 - val_accuracy: 0.5322\n",
      "Epoch 8/20\n",
      "342/342 [==============================] - 298s 873ms/step - loss: 0.9521 - accuracy: 0.6199 - val_loss: 0.9712 - val_accuracy: 0.5439\n",
      "Epoch 9/20\n",
      "342/342 [==============================] - 290s 847ms/step - loss: 0.9475 - accuracy: 0.6330 - val_loss: 0.9677 - val_accuracy: 0.5439\n",
      "Epoch 10/20\n",
      "342/342 [==============================] - 288s 842ms/step - loss: 0.9432 - accuracy: 0.6462 - val_loss: 0.9643 - val_accuracy: 0.5556\n",
      "Epoch 11/20\n",
      "342/342 [==============================] - 293s 856ms/step - loss: 0.9391 - accuracy: 0.6535 - val_loss: 0.9610 - val_accuracy: 0.5673\n",
      "Epoch 12/20\n",
      "342/342 [==============================] - 286s 837ms/step - loss: 0.9352 - accuracy: 0.6594 - val_loss: 0.9577 - val_accuracy: 0.5731\n",
      "Epoch 13/20\n",
      "342/342 [==============================] - 294s 860ms/step - loss: 0.9313 - accuracy: 0.6608 - val_loss: 0.9545 - val_accuracy: 0.5789\n",
      "Epoch 14/20\n",
      "342/342 [==============================] - 292s 853ms/step - loss: 0.9276 - accuracy: 0.6667 - val_loss: 0.9513 - val_accuracy: 0.5848\n",
      "Epoch 15/20\n",
      "342/342 [==============================] - 286s 837ms/step - loss: 0.9239 - accuracy: 0.6711 - val_loss: 0.9481 - val_accuracy: 0.5906\n",
      "Epoch 16/20\n",
      "342/342 [==============================] - 290s 848ms/step - loss: 0.9203 - accuracy: 0.6711 - val_loss: 0.9451 - val_accuracy: 0.5965\n",
      "Epoch 17/20\n",
      "342/342 [==============================] - 288s 841ms/step - loss: 0.9167 - accuracy: 0.6740 - val_loss: 0.9420 - val_accuracy: 0.6023\n",
      "Epoch 18/20\n",
      "342/342 [==============================] - 290s 847ms/step - loss: 0.9132 - accuracy: 0.6769 - val_loss: 0.9390 - val_accuracy: 0.6140\n",
      "Epoch 19/20\n",
      "342/342 [==============================] - 283s 828ms/step - loss: 0.9098 - accuracy: 0.6769 - val_loss: 0.9361 - val_accuracy: 0.6199\n",
      "Epoch 20/20\n",
      "342/342 [==============================] - 298s 872ms/step - loss: 0.9065 - accuracy: 0.6784 - val_loss: 0.9332 - val_accuracy: 0.6316\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import einops\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dimensions\n",
    "HEIGHT = 112\n",
    "WIDTH = 112\n",
    "N_FRAMES = 3\n",
    "BATCH_SIZE = 2\n",
    "MAX_TEXT_FEATURES = 3  # This should match the number of classes from the LLM\n",
    "\n",
    "# Define a simple Conv3D block\n",
    "def Conv3DBlock(filters, kernel_size):\n",
    "    return Sequential([\n",
    "        layers.Conv3D(filters, kernel_size, activation='relu', padding='same'),\n",
    "        layers.MaxPooling3D(pool_size=(1, 2, 2))\n",
    "    ])\n",
    "\n",
    "# Video input model\n",
    "def build_video_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = ResizeVideo(HEIGHT, WIDTH)(inputs)\n",
    "    x = Conv3DBlock(32, (3, 3, 3))(x)\n",
    "    x = Conv3DBlock(64, (3, 3, 3))(x)\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Combined model\n",
    "def build_combined_model(video_input_shape, text_feature_shape):\n",
    "    video_inputs, video_features = build_video_model(video_input_shape)\n",
    "    text_inputs = tf.keras.Input(shape=text_feature_shape)\n",
    "\n",
    "    combined_features = tf.keras.layers.concatenate([video_features, text_inputs])\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(combined_features)  # Assuming 3 classes for classification\n",
    "    model = tf.keras.Model(inputs=[video_inputs, text_inputs], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "video_input_shape = (N_FRAMES, HEIGHT, WIDTH, 3)\n",
    "text_feature_shape = (MAX_TEXT_FEATURES,)\n",
    "\n",
    "model = build_combined_model(video_input_shape, text_feature_shape)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model with a constant learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# FrameGenerator class to preprocess video frames\n",
    "class FrameGenerator:\n",
    "    def __init__(self, paths, labels, features, n_frames, frame_size=(HEIGHT, WIDTH), training=False):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.n_frames = n_frames\n",
    "        self.frame_size = frame_size\n",
    "        self.training = training\n",
    "\n",
    "    def __call__(self):\n",
    "        for video_path, label, feature in zip(self.paths, self.labels, self.features):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "            while len(frames) < self.n_frames:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, self.frame_size)  # Resize frames to smaller size\n",
    "                frame = frame / 255.0  # Normalize\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "            if len(frames) < self.n_frames:\n",
    "                frames.extend([np.zeros(self.frame_size + (3,))] * (self.n_frames - len(frames)))  # Pad with zeros\n",
    "            frames = np.array(frames)\n",
    "\n",
    "            yield (frames, feature), label\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=(N_FRAMES, HEIGHT, WIDTH, 3), dtype=tf.float32), tf.TensorSpec(shape=(MAX_TEXT_FEATURES,), dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    ")\n",
    "\n",
    "def create_dataset(paths, labels, features, n_frames, batch_size, frame_size, training=False):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        FrameGenerator(paths, labels, features, n_frames, frame_size, training=training),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Assuming df is your DataFrame containing video paths, labels, and text features\n",
    "# Ensure you have a DataFrame ready with these columns: 'Video Name', 'Label', 'Text_Features'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_paths = train_df['Video Name'].tolist()\n",
    "train_labels = train_df['Label'].tolist()\n",
    "train_features = np.array(train_df['Text_Features'].tolist())\n",
    "\n",
    "val_paths = test_df['Video Name'].tolist()\n",
    "val_labels = test_df['Label'].tolist()\n",
    "val_features = np.array(test_df['Text_Features'].tolist())\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, train_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH), training=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, val_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH))\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_ds, epochs=20, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76af8f85-a84e-4411-8ec7-b269b1058971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 3, 112, 112, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " resize_video_4 (ResizeVide  (None, 3, 112, 112, 3)       0         ['input_9[0][0]']             \n",
      " o)                                                                                               \n",
      "                                                                                                  \n",
      " video_data_augmentation_2   (None, 3, 112, 112, 3)       0         ['resize_video_4[0][0]']      \n",
      " (VideoDataAugmentation)                                                                          \n",
      "                                                                                                  \n",
      " project_8 (Project)         (None, 3, 112, 112, 32)      128       ['video_data_augmentation_2[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " residual_main_8 (ResidualM  (None, 3, 112, 112, 32)      16480     ['video_data_augmentation_2[0]\n",
      " ain)                                                               [0]']                         \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 3, 112, 112, 32)      0         ['project_8[0][0]',           \n",
      "                                                                     'residual_main_8[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_8 (MaxPoolin  (None, 3, 56, 56, 32)        0         ['add_8[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " project_9 (Project)         (None, 3, 56, 56, 64)        2112      ['max_pooling3d_8[0][0]']     \n",
      "                                                                                                  \n",
      " residual_main_9 (ResidualM  (None, 3, 56, 56, 64)        80384     ['max_pooling3d_8[0][0]']     \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 3, 56, 56, 64)        0         ['project_9[0][0]',           \n",
      "                                                                     'residual_main_9[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_9 (MaxPoolin  (None, 3, 28, 28, 64)        0         ['add_9[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " project_10 (Project)        (None, 3, 28, 28, 128)       8320      ['max_pooling3d_9[0][0]']     \n",
      "                                                                                                  \n",
      " residual_main_10 (Residual  (None, 3, 28, 28, 128)       320512    ['max_pooling3d_9[0][0]']     \n",
      " Main)                                                                                            \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 3, 28, 28, 128)       0         ['project_10[0][0]',          \n",
      "                                                                     'residual_main_10[0][0]']    \n",
      "                                                                                                  \n",
      " global_average_pooling3d_4  (None, 128)                  0         ['add_10[0][0]']              \n",
      "  (GlobalAveragePooling3D)                                                                        \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 131)                  0         ['global_average_pooling3d_4[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'input_10[0][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 3)                    396       ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 428332 (1.63 MB)\n",
      "Trainable params: 428332 (1.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "684/684 [==============================] - 580s 840ms/step - loss: 1.2764 - accuracy: 0.4371 - val_loss: 1.1088 - val_accuracy: 0.4561\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 565s 826ms/step - loss: 1.0481 - accuracy: 0.4459 - val_loss: 1.0853 - val_accuracy: 0.4561\n",
      "Epoch 3/10\n",
      "684/684 [==============================] - 575s 840ms/step - loss: 1.0256 - accuracy: 0.4240 - val_loss: 1.0346 - val_accuracy: 0.4561\n",
      "Epoch 4/10\n",
      "684/684 [==============================] - 580s 848ms/step - loss: 1.0172 - accuracy: 0.4298 - val_loss: 1.0245 - val_accuracy: 0.4561\n",
      "Epoch 5/10\n",
      "684/684 [==============================] - 591s 864ms/step - loss: 1.0089 - accuracy: 0.4342 - val_loss: 1.0099 - val_accuracy: 0.4561\n",
      "Epoch 6/10\n",
      "684/684 [==============================] - 568s 830ms/step - loss: 1.0047 - accuracy: 0.4547 - val_loss: 1.0358 - val_accuracy: 0.4561\n",
      "Epoch 7/10\n",
      "684/684 [==============================] - 565s 826ms/step - loss: 1.0010 - accuracy: 0.4474 - val_loss: 1.0008 - val_accuracy: 0.4561\n",
      "Epoch 8/10\n",
      "684/684 [==============================] - 572s 836ms/step - loss: 0.9958 - accuracy: 0.4488 - val_loss: 0.9990 - val_accuracy: 0.4561\n",
      "Epoch 9/10\n",
      "684/684 [==============================] - 571s 835ms/step - loss: 0.9937 - accuracy: 0.4532 - val_loss: 0.9988 - val_accuracy: 0.4561\n",
      "Epoch 10/10\n",
      "684/684 [==============================] - 555s 811ms/step - loss: 0.9912 - accuracy: 0.4547 - val_loss: 0.9971 - val_accuracy: 0.6374\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import einops\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dimensions\n",
    "HEIGHT = 112\n",
    "WIDTH = 112\n",
    "N_FRAMES = 3\n",
    "BATCH_SIZE = 1\n",
    "MAX_TEXT_FEATURES = 3  # This should match the number of classes from the LLM\n",
    "\n",
    "# Define Conv2Plus1D layer\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, kernel_size[1], kernel_size[2]), padding=padding),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(kernel_size[0], 1, 1), padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Define Project layer\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv3D(filters, kernel_size=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Define ResidualMain layer\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dropout_rate=0.3, l2_strength=0.01):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Add residual block\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    out = ResidualMain(filters, kernel_size)(input)\n",
    "    res = input\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "    return layers.add([res, out])\n",
    "\n",
    "# Resize video frames\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Data augmentation for video frames\n",
    "class VideoDataAugmentation(layers.Layer):\n",
    "    def __init__(self, frame_size):\n",
    "        super().__init__()\n",
    "        self.frame_size = frame_size\n",
    "        self.augmentation_layer = Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.1),\n",
    "            layers.RandomCrop(self.frame_size[0], self.frame_size[1])\n",
    "        ])\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.augmentation_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Video input model\n",
    "def build_video_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = ResizeVideo(HEIGHT, WIDTH)(inputs)\n",
    "    x = VideoDataAugmentation((HEIGHT, WIDTH))(x)  # Apply augmentation\n",
    "    x = add_residual_block(x, filters=32, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=64, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=128, kernel_size=(3, 3, 3))  # New block\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Combined model\n",
    "def build_combined_model(video_input_shape, text_feature_shape):\n",
    "    video_inputs, video_features = build_video_model(video_input_shape)\n",
    "    text_inputs = tf.keras.Input(shape=text_feature_shape)\n",
    "\n",
    "    combined_features = tf.keras.layers.concatenate([video_features, text_inputs])\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(combined_features)  # Assuming 3 classes for classification\n",
    "    model = tf.keras.Model(inputs=[video_inputs, text_inputs], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "video_input_shape = (N_FRAMES, HEIGHT, WIDTH, 3)\n",
    "text_feature_shape = (MAX_TEXT_FEATURES,)\n",
    "\n",
    "model = build_combined_model(video_input_shape, text_feature_shape)\n",
    "model.summary()\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.95\n",
    ")\n",
    "\n",
    "# Compile the model with the learning rate schedule\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# FrameGenerator class to preprocess video frames\n",
    "class FrameGenerator:\n",
    "    def __init__(self, paths, labels, features, n_frames, frame_size=(HEIGHT, WIDTH), training=False):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.n_frames = n_frames\n",
    "        self.frame_size = frame_size\n",
    "        self.training = training\n",
    "\n",
    "    def __call__(self):\n",
    "        for video_path, label, feature in zip(self.paths, self.labels, self.features):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "            while len(frames) < self.n_frames:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, self.frame_size)  # Resize frames to smaller size\n",
    "                frame = frame / 255.0  # Normalize\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "            if len(frames) < self.n_frames:\n",
    "                frames.extend([np.zeros(self.frame_size + (3,))] * (self.n_frames - len(frames)))  # Pad with zeros\n",
    "            frames = np.array(frames)\n",
    "\n",
    "            yield (frames, feature), label\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=(N_FRAMES, HEIGHT, WIDTH, 3), dtype=tf.float32), tf.TensorSpec(shape=(MAX_TEXT_FEATURES,), dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    ")\n",
    "\n",
    "def create_dataset(paths, labels, features, n_frames, batch_size, frame_size, training=False):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        FrameGenerator(paths, labels, features, n_frames, frame_size, training=training),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Assuming df is your DataFrame containing video paths, labels, and text features\n",
    "# Ensure you have a DataFrame ready with these columns: 'Video Name', 'Label', 'Text_Features'\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_paths = train_df['Video Name'].tolist()\n",
    "train_labels = train_df['Label'].tolist()\n",
    "train_features = np.array(train_df['Text_Features'].tolist())\n",
    "\n",
    "val_paths = test_df['Video Name'].tolist()\n",
    "val_labels = test_df['Label'].tolist()\n",
    "val_features = np.array(test_df['Text_Features'].tolist())\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, train_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH), training=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, val_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH))\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Callbacks for early stopping and checkpointing\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1710482-0639-4166-8b6b-dd090b0a2566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, 3, 112, 112, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " resize_video_6 (ResizeVide  (None, 3, 112, 112, 3)       0         ['input_13[0][0]']            \n",
      " o)                                                                                               \n",
      "                                                                                                  \n",
      " video_data_augmentation_4   (None, 3, 112, 112, 3)       0         ['resize_video_6[0][0]']      \n",
      " (VideoDataAugmentation)                                                                          \n",
      "                                                                                                  \n",
      " project_14 (Project)        (None, 3, 112, 112, 32)      128       ['video_data_augmentation_4[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " residual_main_14 (Residual  (None, 3, 112, 112, 32)      5312      ['video_data_augmentation_4[0]\n",
      " Main)                                                              [0]']                         \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 3, 112, 112, 32)      0         ['project_14[0][0]',          \n",
      "                                                                     'residual_main_14[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling3d_12 (MaxPooli  (None, 3, 56, 56, 32)        0         ['add_14[0][0]']              \n",
      " ng3D)                                                                                            \n",
      "                                                                                                  \n",
      " project_15 (Project)        (None, 3, 56, 56, 64)        2112      ['max_pooling3d_12[0][0]']    \n",
      "                                                                                                  \n",
      " residual_main_15 (Residual  (None, 3, 56, 56, 64)        35520     ['max_pooling3d_12[0][0]']    \n",
      " Main)                                                                                            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 3, 56, 56, 64)        0         ['project_15[0][0]',          \n",
      "                                                                     'residual_main_15[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling3d_13 (MaxPooli  (None, 3, 28, 28, 64)        0         ['add_15[0][0]']              \n",
      " ng3D)                                                                                            \n",
      "                                                                                                  \n",
      " project_16 (Project)        (None, 3, 28, 28, 128)       8320      ['max_pooling3d_13[0][0]']    \n",
      "                                                                                                  \n",
      " residual_main_16 (Residual  (None, 3, 28, 28, 128)       140672    ['max_pooling3d_13[0][0]']    \n",
      " Main)                                                                                            \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 3, 28, 28, 128)       0         ['project_16[0][0]',          \n",
      "                                                                     'residual_main_16[0][0]']    \n",
      "                                                                                                  \n",
      " global_average_pooling3d_6  (None, 128)                  0         ['add_16[0][0]']              \n",
      "  (GlobalAveragePooling3D)                                                                        \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)       [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 131)                  0         ['global_average_pooling3d_6[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'input_14[0][0]']            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 3)                    396       ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192460 (751.80 KB)\n",
      "Trainable params: 191564 (748.30 KB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "171/171 [==============================] - 402s 2s/step - loss: 1.0683 - accuracy: 0.4313 - val_loss: 1.0720 - val_accuracy: 0.4035\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 410s 2s/step - loss: 1.0304 - accuracy: 0.4371 - val_loss: 1.0432 - val_accuracy: 0.4561\n",
      "Epoch 3/30\n",
      "171/171 [==============================] - 406s 2s/step - loss: 1.0211 - accuracy: 0.4503 - val_loss: 1.0178 - val_accuracy: 0.4561\n",
      "Epoch 4/30\n",
      "171/171 [==============================] - 410s 2s/step - loss: 1.0157 - accuracy: 0.4357 - val_loss: 1.0181 - val_accuracy: 0.6199\n",
      "Epoch 5/30\n",
      "171/171 [==============================] - 402s 2s/step - loss: 1.0115 - accuracy: 0.4342 - val_loss: 2.5929 - val_accuracy: 0.4035\n",
      "Epoch 6/30\n",
      "171/171 [==============================] - 406s 2s/step - loss: 1.0189 - accuracy: 0.4371 - val_loss: 1.1146 - val_accuracy: 0.4561\n",
      "Epoch 7/30\n",
      "171/171 [==============================] - 404s 2s/step - loss: 1.0074 - accuracy: 0.4357 - val_loss: 1.0239 - val_accuracy: 0.6082\n",
      "Epoch 8/30\n",
      "171/171 [==============================] - 418s 2s/step - loss: 1.0048 - accuracy: 0.4576 - val_loss: 1.0321 - val_accuracy: 0.5789\n",
      "Epoch 9/30\n",
      "171/171 [==============================] - 400s 2s/step - loss: 1.0030 - accuracy: 0.4503 - val_loss: 1.0298 - val_accuracy: 0.4444\n",
      "Epoch 10/30\n",
      "171/171 [==============================] - 406s 2s/step - loss: 1.0018 - accuracy: 0.4561 - val_loss: 1.0257 - val_accuracy: 0.4035\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import einops\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dimensions\n",
    "HEIGHT = 112\n",
    "WIDTH = 112\n",
    "N_FRAMES = 3\n",
    "BATCH_SIZE = 4  # Increased batch size for better gradient estimation\n",
    "MAX_TEXT_FEATURES = 3\n",
    "\n",
    "# Define Conv2Plus1D layer with Batch Normalization\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, kernel_size[1], kernel_size[2]), padding=padding),\n",
    "            layers.BatchNormalization(),  # Batch normalization for stabilization\n",
    "            layers.ReLU(),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(kernel_size[0], 1, 1), padding=padding),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Dropout(dropout_rate)  # Dropout for regularization\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Define Project layer\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv3D(filters, kernel_size=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Define ResidualMain layer with L2 regularization\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dropout_rate=0.3, l2_strength=1e-4):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same', dropout_rate=dropout_rate),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(l2_strength))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# Add residual block with projection for skip connection\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    out = ResidualMain(filters, kernel_size)(input)\n",
    "    res = input\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "    return layers.add([res, out])\n",
    "\n",
    "# Resize video frames\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Data augmentation for video frames\n",
    "class VideoDataAugmentation(layers.Layer):\n",
    "    def __init__(self, frame_size):\n",
    "        super().__init__()\n",
    "        self.frame_size = frame_size\n",
    "        self.augmentation_layer = Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.1),\n",
    "            layers.RandomCrop(self.frame_size[0], self.frame_size[1])\n",
    "        ])\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.augmentation_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# Video input model\n",
    "def build_video_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = ResizeVideo(HEIGHT, WIDTH)(inputs)\n",
    "    x = VideoDataAugmentation((HEIGHT, WIDTH))(x)\n",
    "    x = add_residual_block(x, filters=32, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=64, kernel_size=(3, 3, 3))\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
    "    x = add_residual_block(x, filters=128, kernel_size=(3, 3, 3))\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Combined model\n",
    "def build_combined_model(video_input_shape, text_feature_shape):\n",
    "    video_inputs, video_features = build_video_model(video_input_shape)\n",
    "    text_inputs = tf.keras.Input(shape=text_feature_shape)\n",
    "\n",
    "    combined_features = tf.keras.layers.concatenate([video_features, text_inputs])\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(combined_features)  # Assuming 3 classes for classification\n",
    "    model = tf.keras.Model(inputs=[video_inputs, text_inputs], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "video_input_shape = (N_FRAMES, HEIGHT, WIDTH, 3)\n",
    "text_feature_shape = (MAX_TEXT_FEATURES,)\n",
    "\n",
    "model = build_combined_model(video_input_shape, text_feature_shape)\n",
    "model.summary()\n",
    "\n",
    "# Learning rate scheduler with reduced decay\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.95\n",
    ")\n",
    "\n",
    "# Compile the model with the learning rate schedule\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# FrameGenerator class to preprocess video frames\n",
    "class FrameGenerator:\n",
    "    def __init__(self, paths, labels, features, n_frames, frame_size=(HEIGHT, WIDTH), training=False):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.n_frames = n_frames\n",
    "        self.frame_size = frame_size\n",
    "        self.training = training\n",
    "\n",
    "    def __call__(self):\n",
    "        for video_path, label, feature in zip(self.paths, self.labels, self.features):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "            while len(frames) < self.n_frames:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, self.frame_size)\n",
    "                frame = frame / 255.0\n",
    "                frames.append(frame)\n",
    "            cap.release()\n",
    "            if len(frames) < self.n_frames:\n",
    "                frames.extend([np.zeros(self.frame_size + (3,))] * (self.n_frames - len(frames)))\n",
    "            frames = np.array(frames)\n",
    "\n",
    "            yield (frames, feature), label\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=(N_FRAMES, HEIGHT, WIDTH, 3), dtype=tf.float32), tf.TensorSpec(shape=(MAX_TEXT_FEATURES,), dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    ")\n",
    "\n",
    "def create_dataset(paths, labels, features, n_frames, batch_size, frame_size, training=False):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        FrameGenerator(paths, labels, features, n_frames, frame_size, training=training),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Assuming df is your DataFrame containing video paths, labels, and text features\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_paths = train_df['Video Name'].tolist()\n",
    "train_labels = train_df['Label'].tolist()\n",
    "train_features = np.array(train_df['Text_Features'].tolist())\n",
    "\n",
    "val_paths = test_df['Video Name'].tolist()\n",
    "val_labels = test_df['Label'].tolist()\n",
    "val_features = np.array(test_df['Text_Features'].tolist())\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, train_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH), training=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, val_features, N_FRAMES, BATCH_SIZE, frame_size=(HEIGHT, WIDTH))\n",
    "\n",
    "# Callbacks for early stopping and checkpointing\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3100d-41a9-4fe8-ac6e-57a30cbb604d",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451c0e94-9ab7-4fcb-86ca-e847568491b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0763786d-ae87-4bc6-9b35-78e2a12d21e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m(), model_path)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Move the model to the appropriate device\u001b[39;00m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "model_path = 'hybrid_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loaded_model.to(device)\n",
    "print(f\"Model loaded from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a30083-6212-419b-b8d3-be19b20b5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to hybrid_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from hybrid_model.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load and initialize the model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# Save the model's state dictionary\n",
    "model_path = 'hybrid_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Load the model for inference or further training\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# Make sure the model path exists before loading\n",
    "try:\n",
    "    loaded_model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38f27df5-f4e6-4ef3-a554-c57dfa83619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_directory = './models/'\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "model_path = os.path.join(save_directory, 'hybrid_model.pth')\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
