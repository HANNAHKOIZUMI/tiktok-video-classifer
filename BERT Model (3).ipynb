{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0164d49c-598d-4ca0-9d82-32e949159338",
   "metadata": {},
   "source": [
    "# Setup / Clear Kernel Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11871afa-8518-49ad-8cb0-81587128f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01704412-7ebf-4df8-9a43-421587f90ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf8590f-924d-4614-8693-09c6787014eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transcription'] = df['Transcription'].fillna('').astype(str)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411503c0-dde6-40b6-a8c6-846681a956f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Link</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>sort_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.tiktok.com/@1tashyat/video/7359361...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ST Anselm College. She's a Republican. This w...</td>\n",
       "      <td>1_mp4_trial_2.json</td>\n",
       "      <td>ST Anselm College. She's a Republican. This wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://www.tiktok.com/@monkeman317/video/7357...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Said though, that if you did run for presiden...</td>\n",
       "      <td>2_mp4_trial_2.json</td>\n",
       "      <td>Said though, that if you did run for president...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://www.tiktok.com/@bwtgrils_/video/736257...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah.'</td>\n",
       "      <td>3_mp4_trial_2.json</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                               Link  Label  \\\n",
       "0    1.0  https://www.tiktok.com/@1tashyat/video/7359361...      1   \n",
       "1    2.0  https://www.tiktok.com/@monkeman317/video/7357...      1   \n",
       "2    3.0  https://www.tiktok.com/@bwtgrils_/video/736257...      1   \n",
       "\n",
       "                                                Text            FileName  \\\n",
       "0  \"ST Anselm College. She's a Republican. This w...  1_mp4_trial_2.json   \n",
       "1  \"Said though, that if you did run for presiden...  2_mp4_trial_2.json   \n",
       "2                                             Yeah.'  3_mp4_trial_2.json   \n",
       "\n",
       "                                       Transcription  sort_key  \n",
       "0  ST Anselm College. She's a Republican. This wi...         1  \n",
       "1  Said though, that if you did run for president...         2  \n",
       "2                                              Yeah.         3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad2da3-8433-4e64-a4d3-8308451d4a20",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05645a15-d5eb-4280-ac40-0d5ff2073a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-08-04 21:55:42.280592: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing Train Data: 35it [06:24, 10.99s/it]\n",
      "Processing Validation Data: 9it [01:31, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 41.90%\n",
      "Validation accuracy: 43.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Assuming three classes\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, model):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Ensure the text is a string\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "\n",
    "        # Tokenize the text\n",
    "        encoded_text = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        encoded_text = {key: value.squeeze(0) for key, value in encoded_text.items()}\n",
    "        return encoded_text, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def process_in_batches(self, batch_size, optimizer, scheduler):\n",
    "        dataloader = DataLoader(self, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "        all_outputs = []\n",
    "        self.model.train()\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            all_outputs.append(outputs.logits.detach().cpu().numpy())\n",
    "\n",
    "            # Clear unnecessary data\n",
    "            del inputs, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return np.concatenate(all_outputs, axis=0)\n",
    "\n",
    "def split_data(texts, labels, chunk_size):\n",
    "    for i in range(0, len(texts), chunk_size):\n",
    "        yield texts[i:i + chunk_size], labels[i:i + chunk_size]\n",
    "\n",
    "df['Text'].fillna('', inplace=True) \n",
    "df['Label'].fillna(0, inplace=True)  \n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['Text'].tolist(), df['Label'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "chunk_size = 20  \n",
    "batch_size = 8 \n",
    "learning_rate = 1e-5  \n",
    "num_epochs = 3 \n",
    "step_size = 3 \n",
    "gamma = 0.8 \n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  # Use AdamW optimizer\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "all_train_outputs = []\n",
    "all_val_outputs = []\n",
    "\n",
    "for train_chunk_texts, train_chunk_labels in tqdm(split_data(train_texts, train_labels, chunk_size), desc=\"Processing Train Data\"):\n",
    "    train_dataset = SentimentDataset(train_chunk_texts, train_chunk_labels, tokenizer, model)\n",
    "    train_outputs = train_dataset.process_in_batches(batch_size, optimizer, scheduler)\n",
    "    all_train_outputs.append(train_outputs)\n",
    "\n",
    "for val_chunk_texts, val_chunk_labels in tqdm(split_data(val_texts, val_labels, chunk_size), desc=\"Processing Validation Data\"):\n",
    "    val_dataset = SentimentDataset(val_chunk_texts, val_chunk_labels, tokenizer, model)\n",
    "    val_outputs = val_dataset.process_in_batches(batch_size, optimizer, scheduler)\n",
    "    all_val_outputs.append(val_outputs)\n",
    "\n",
    "all_train_outputs = np.concatenate(all_train_outputs, axis=0)\n",
    "all_val_outputs = np.concatenate(all_val_outputs, axis=0)\n",
    "\n",
    "def evaluate_model(outputs, labels):\n",
    "    predicted_labels = np.argmax(outputs, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == labels)\n",
    "    return accuracy\n",
    "\n",
    "train_accuracy = evaluate_model(all_train_outputs, np.array(train_labels))\n",
    "val_accuracy = evaluate_model(all_val_outputs, np.array(val_labels))\n",
    "\n",
    "print(\"Training accuracy: {:.2f}%\".format(train_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.2f}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c9c316-cffc-49ce-8bfa-09ad277c5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-08-04 22:14:05.111329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing Train Data: 685it [15:35,  1.36s/it]\n",
      "Processing Validation Data: 172it [03:42,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 77.37%\n",
      "Validation accuracy: 79.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3) \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded_text = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        encoded_text = {key: value.squeeze(0) for key, value in encoded_text.items()}\n",
    "        return encoded_text, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def process_in_batches(texts, labels, batch_size):\n",
    "    dataset = SentimentDataset(texts, labels, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    all_outputs = []\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "    for epoch in range(1): \n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            all_outputs.append(outputs.logits.detach().cpu().numpy())\n",
    "\n",
    "            # Clear unnecessary data\n",
    "            del inputs, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return np.concatenate(all_outputs, axis=0)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['Transcription'].tolist(), df['Label'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "def split_data(texts, labels, chunk_size):\n",
    "    for i in range(0, len(texts), chunk_size):\n",
    "        yield texts[i:i + chunk_size], labels[i:i + chunk_size]\n",
    "\n",
    "chunk_size = 1  \n",
    "batch_size = 1\n",
    "\n",
    "all_train_outputs = []\n",
    "all_val_outputs = []\n",
    "\n",
    "for train_chunk_texts, train_chunk_labels in tqdm(split_data(train_texts, train_labels, chunk_size), desc=\"Processing Train Data\"):\n",
    "    train_outputs = process_in_batches(train_chunk_texts, train_chunk_labels, batch_size)\n",
    "    all_train_outputs.append(train_outputs)\n",
    "\n",
    "for val_chunk_texts, val_chunk_labels in tqdm(split_data(val_texts, val_labels, chunk_size), desc=\"Processing Validation Data\"):\n",
    "    val_outputs = process_in_batches(val_chunk_texts, val_chunk_labels, batch_size)\n",
    "    all_val_outputs.append(val_outputs)\n",
    "\n",
    "all_train_outputs = np.concatenate(all_train_outputs, axis=0)\n",
    "all_val_outputs = np.concatenate(all_val_outputs, axis=0)\n",
    "\n",
    "def evaluate_model(outputs, labels):\n",
    "    predicted_labels = np.argmax(outputs, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == labels)\n",
    "    return accuracy\n",
    "\n",
    "train_accuracy = evaluate_model(all_train_outputs, np.array(train_labels))\n",
    "val_accuracy = evaluate_model(all_val_outputs, np.array(val_labels))\n",
    "\n",
    "print(\"Training accuracy: {:.2f}%\".format(train_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.2f}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f2d1d-f438-409b-801c-64f604002b06",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bfd6a4-8b04-4ef8-bb1b-b13a7ff4e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f9ca21-acd2-4721-8b65-4144dbf1d20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to bert_model.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = 'bert_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
